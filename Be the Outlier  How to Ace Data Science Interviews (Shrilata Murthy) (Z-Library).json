[
    {
        "text": "new degree press copyright \u00a9 2020 shrilata murthy all rights reserved."
    },
    {
        "text": "be the outlier how to ace data science interviews isbn 978-1-64137-985-4 paperback 978-1-64137-877-2 kindle ebook 978-1-64137-878-9 ebook"
    },
    {
        "text": "to ganapati and samyra, for always being there."
    },
    {
        "text": "contents introduction part 1 getting started what is data science?"
    },
    {
        "text": "what is the market looking for?"
    },
    {
        "text": "what do you want to do?"
    },
    {
        "text": "part 2 cracking the technical rounds modeling and machine learning questions probability, statistics, and experimental design programming questions case questions part 3 showcasing the right experience tell me about a project you worked on presentation interview take-home exam behavioral interview part 4 putting your best foot forward crafting a data science resume data science portfolio part 5 last but not the least wrapping up acknowledgments additional resources appendix about the author"
    },
    {
        "text": "introduction if you work in the field of data science, you probably know how daunting the interview process can be."
    },
    {
        "text": "as a candidate, you are being tested on your skills in statistics, technology, business, and countless other subsections of these broad categories."
    },
    {
        "text": "this can make the process overwhelming, and you may feel unprepared no matter how much you've practiced."
    },
    {
        "text": "as a data scientist myself, i know how nerve-racking preparing for interviews can be, and they\u2019re even worse when you aren\u2019t sure what to expect."
    },
    {
        "text": "but if you weed through and peel back the layers, you will uncover a pattern\u2014a pattern that is intuitive and speaks to how the different elements in a data scientist\u2019s job role come together."
    },
    {
        "text": "that\u2019s exactly why i wrote this book, which covers all aspects of a data science interview in today\u2019s industry and highlights how you can differentiate yourself from your peers and be the outlier."
    },
    {
        "text": "my data science journey began back in 2013 when i joined the masters in analytics program at northwestern university."
    },
    {
        "text": "ours was the second graduating cohort at northwestern from the program at the time."
    },
    {
        "text": "from then to now, the data science field has evolved a lot over the past years."
    },
    {
        "text": "indeed, one of the top job sites reported that data science postings have rocketed 256 percent\u2014more than tripling since december 2013.1 the industry, overall, has seen staggering growth in the use of data science and machine learning in its day-to-day business, and this has translated into an increase in data science jobs over the years."
    },
    {
        "text": "over the last decade, not only have jobs available for data science seen incredible growth, but the nature of the job role itself has evolved."
    },
    {
        "text": "closer to graduation, as i was preparing for interviews, i realized how data science roles differed across companies depending on why, what, and how data science is"
    },
    {
        "text": "used in a company."
    },
    {
        "text": "needless to say, the strategy to prepare for interviews for each company changed accordingly."
    },
    {
        "text": "i made extensive notes about the key concepts i prepared for, programming questions i was typically asked, and probability questions i was quizzed on."
    },
    {
        "text": "every now and then, when prospective data scientists reached out to me to get pointers on how to crack these interviews, i found myself referring to my notes from my graduation days."
    },
    {
        "text": "although the notes i made were current to when i was interviewing, i saw gaps in what i had collated versus what the industry is asking for now."
    },
    {
        "text": "while i was up to date with how the interview process and candidate expectations have changed in the industry that i work in, i was curious to know how things have progressed industry wide."
    },
    {
        "text": "i reached out to my network in the field, including those who worked at consulting companies, product-based and technology firms, industry-specific companies, startups, and everything in between."
    },
    {
        "text": "i learned a lot in the process and did my best to relay this knowledge to the folks who reached out to me with questions of this nature."
    },
    {
        "text": "when talking to people on both sides of the table\u2014job seekers and experienced data scientists\u2014i noticed that while good material to prepare for software-programmer, product-manager, and data-analyst types of roles was out there, there was a lack of comprehensive material for a data science interview."
    },
    {
        "text": "i found many question banks online with pointers to various types of questions asked, but not a one-stop-shop resource to prepare for data science interviews."
    },
    {
        "text": "with this book, i will walk you through the different types of data science roles and the specific skill sets you need to focus on when preparing for the pertinent interview."
    },
    {
        "text": "this book will also provide you with sample answers that have been vetted by experienced data scientists with tips and tricks to help you stand out as a stellar candidate."
    },
    {
        "text": "whether you are an aspiring data scientist looking for a break in the field, a data scientist looking for a job change, or just someone who wants to learn more about data science, this book is for you."
    },
    {
        "text": "i wish you the very best as you prepare for your next interview."
    },
    {
        "text": "a strong foundation and practice will get you where you aim to be!"
    },
    {
        "text": "1 \u201cdata scientist: a hot job that pays well,\u201d indeed hiring lab, us, accessed may 5, 2020."
    },
    {
        "text": "part 1 getting started"
    },
    {
        "text": "what is data science?"
    },
    {
        "text": "before we jump into the nitty-gritty of a data science-focused interview, let\u2019s take a step back and understand what data science is and how it all started."
    },
    {
        "text": "at a grassroots level, i like to think of the data science role as a combination of a traditional researcher, a computer programmer, and a business analyst."
    },
    {
        "text": "the graphic below helps paint this picture of the three key skill sets coming together and forming what we now call data science."
    },
    {
        "text": "who is a data scientist?"
    },
    {
        "text": "essentially, i like to think of a data scientist as someone who can extract meaning from complex data and assist in decision-making."
    },
    {
        "text": "a data scientist makes use of methods from statistics and machine learning for their analysis and has the technical skills to codify their work."
    },
    {
        "text": "the term \u201cdata science\u201d was coined in 2008 by dj patil and jeff hammerbacher, who were then the respective leads of data and analytics efforts at linkedin and facebook."
    },
    {
        "text": "in an interview with observer, patil, the former chief data scientist for the obama administration, said, \u201ci was at linkedin building the data team, and jeff hammerbacher [co-founder of cloudera] was bustling at facebook\u2019s data team, and we would collaborate and compare notes sometimes."
    },
    {
        "text": "one of the things we realized was that we didn\u2019t know what to call ourselves.\u201d2 when asked about the definition of the data scientist role, patil said, \u201ci am generally opposed to trying to define it too rigorously."
    },
    {
        "text": "the important thing is how you use data to interact with the world, study it, and try to come up with new things."
    },
    {
        "text": "some of those things are new products, like a self-driving car or your weather app."
    },
    {
        "text": "others are data analyses used to help people make assessment for everything from loans to health care decisions."
    },
    {
        "text": "there are all kinds of data scientists."
    },
    {
        "text": "maybe the title survives and maybe it turns into something else."
    },
    {
        "text": "but i think the most powerful thing here is that we are using data in novel ways to build things.\u201d3 more than a decade later, the title not only survives\u2014it thrives and continues to evolve."
    },
    {
        "text": "the impact of data science on the job market is huge."
    },
    {
        "text": "one can find multiple reports online that speak to this in depth."
    },
    {
        "text": "according to linkedin\u2019s third annual us emerging jobs report, the data scientist role has seen a 37 percent annual growth per this report and is ranked third among the top fifteen emerging jobs in the us.4 data science skills proliferate across industries and aren\u2019t just predominant in any one industry alone."
    },
    {
        "text": "when i spoke to people working in consulting, who worked across industries to serve their clients in the analytics space, they mentioned an increasing use of data science applications in the financial, consumer products, healthcare, and insurance industries."
    },
    {
        "text": "as different industries continue to invest in data science resulting in more innovation in the field, the need for a workforce to serve in this rapidly emerging job market is growing."
    },
    {
        "text": "2 sissi cao, \u201cwhat on earth is a data scientist?"
    },
    {
        "text": "the buzzword\u2019s inventor dj patil spills all,\u201d observer, november 9, 2019."
    },
    {
        "text": "3 sissi cao, \u201cwhat on earth is a data scientist?"
    },
    {
        "text": "the buzzword\u2019s inventor dj patil spills all,\u201d observer, november 9, 2019."
    },
    {
        "text": "4 \u201clinkedin: 2020 emerging jobs report,\u201d linkedin, accessed may 16, 2020."
    },
    {
        "text": "what is the market looking for?"
    },
    {
        "text": "now that we understand what data science entails, we must also understand what skills the market is looking for in a data scientist."
    },
    {
        "text": "when i spoke to laura siahaan, business it data scientist and team lead at nasa\u2019s jet propulsion laboratory, she explained that a key aspect of her job involves communicating analytical findings to a non-technical audience."
    },
    {
        "text": "hence, when interviewing data scientists, one of the main skills she looks for is the ability to explain complex data science concepts in a simple and precise manner."
    },
    {
        "text": "she highlighted the ability to tell a story using data as a differentiator among candidates."
    },
    {
        "text": "translating complex findings into actionable insights can be a daunting task at times, but having this skill set in your back pocket will make your work rewarding."
    },
    {
        "text": "a consultant in the analytics space from the big four said, \u201cwhen you apply for a role in a consulting company, you are a consultant first then a data scientist."
    },
    {
        "text": "it is crucial to be a strategic thinker and understand holistically the business problem that you are trying to solve."
    },
    {
        "text": "when you absorb all the information at a macro level to begin with, it becomes a lot easier to deep dive and solve the problem analytically."
    },
    {
        "text": "with the business requirements and expectations nailed down, it should then come naturally for a data scientist to formulate a data request and recommend analytical techniques to be used to solve a problem.\u201d it was then that i realized how important having a bird\u2019s eye view of the"
    },
    {
        "text": "problem at all times is."
    },
    {
        "text": "as a data scientist, getting lost in the weeds is easy."
    },
    {
        "text": "having this as a constant reminder will help course correct if needed!"
    },
    {
        "text": "while both of these inputs touch more on the non-tangible skill sets of problem solving and effective communication, roles exist where the knowledge of a particular tool or programming language is a must."
    },
    {
        "text": "a product manager with google told me their team almost always uses python as the language of choice."
    },
    {
        "text": "given that their team heavily relies on deep learning techniques to conduct their analysis, knowledge of pytorch and tensorflow is required."
    },
    {
        "text": "after having conversations with people in the data science field, i noticed the wide range of skill sets in demand in the marketplace today."
    },
    {
        "text": "the visual below captures the different answers i received from data scientists across industries."
    },
    {
        "text": "what are companies looking for in a data scientist?"
    },
    {
        "text": "with such a wide range of answers, i sought to understand how these skill sets vary across different data science roles."
    },
    {
        "text": "if you search for \u201cdata scientist\u201d job openings on linkedin or any other job posting site, you will notice that the results are listed under varying job titles."
    },
    {
        "text": "some of the popular ones are"
    },
    {
        "text": "artificial intelligence specialist, data scientist, machine learning engineer, data analyst, data visualization specialist, business analyst, data engineer, and data architect."
    },
    {
        "text": "i grouped these for brevity and to allow for a more strategic approach for anyone preparing for an interview in these fields."
    },
    {
        "text": "machine learning engineer: per linkedin\u2019s emerging jobs report, this role encompasses skills in the areas of machine learning, deep learning, tensorflow, python, and natural language processing.5 here are a few highlights of job requirements posted by apple and spotify for the machine learning engineer role."
    },
    {
        "text": "apple: \u2013 expertise and experience in various facets of machine learning and natural language processing, such as classification, feature engineering, information extraction, structured prediction, clustering, semi-supervised learning, topic modeling, and ranking."
    },
    {
        "text": "\u2013 programming experience in one or more of the following: java, c++, python or equivalent."
    },
    {
        "text": "\u2013 contributions to research communities, e.g., acl, nips, icml, and cvpr."
    },
    {
        "text": "spotify: \u2013 you have hands-on experience implementing production machine learning systems at scale in java, scala, python, or similar languages."
    },
    {
        "text": "experience with xgboost, tensorflow is also a plus."
    },
    {
        "text": "\u2013 you care about agile software processes, data-driven development, reliability, and disciplined experimentation."
    },
    {
        "text": "as you may notice in both job descriptions, they emphasize being proficient at an at-scale programming language such as python or java."
    },
    {
        "text": "they also have a distinguished requirement of being well-versed in the latest in machine learning techniques."
    },
    {
        "text": "a machine learning engineer typically will have a chance to work on the state-of-the-art technological environments and have a chance"
    },
    {
        "text": "to use the cutting-edge techniques to differentiate the company\u2019s product in the competitive market."
    },
    {
        "text": "data scientist: touted as \u201cthe sexiest job of the twenty-first century,\u201d the data scientist role at a broader level encompasses knowledge of descriptive, predictive, and prescriptive analytics.6 a few nuggets of the job requirements from quantumblack, a mckinsey company, showcase that this role popularly requires knowledge of machine learning algorithms, python, r, and sql."
    },
    {
        "text": "experience in statistical modelling and machine learning techniques."
    },
    {
        "text": "programming experience in at least two of the following languages: r, python, scala, sql."
    },
    {
        "text": "experience in applying data science methods to business problems."
    },
    {
        "text": "good presentation and communication skills, with the ability to explain complex analytical concepts to people from other fields."
    },
    {
        "text": "business analytics specialist: this role is different from the machine learning engineer and data scientist role in that it has more emphasis on use case development for analytics and its requirement of the specific industry/domain knowledge in which it is applicable."
    },
    {
        "text": "this role also requires excellent communication and presentation skills, considering you need to be able to get buy-ins from key stakeholders in the organization, who are often an executive audience of c-suite members."
    },
    {
        "text": "additionally, the role may require good interpersonal skills to enable adoption of analytical techniques through the organization."
    },
    {
        "text": "here\u2019s a highlight from unilever\u2019s job posting for a business analytics manager: serve as the trusted data and analytics consultant for leaders within the organization that provide products-solutions that rapidly solve for business issues."
    },
    {
        "text": "delivery of the total joint business plan priorities between different teams."
    },
    {
        "text": "ensure the career development of the in-market data scientist team as a talent pipeline into the cluster hubs."
    },
    {
        "text": "additionally, note the below job requirement snippets for the business analytics role, as they occurred in multiple other companies as well."
    },
    {
        "text": "expert knowledge in statistics (regression, clustering, random forrest, decision trees, optimization, time series, probability, and other related advanced methodologies)."
    },
    {
        "text": "working knowledge of a visualization tool such as microsoft powerbi, qlikview, or tableau."
    },
    {
        "text": "working knowledge and basic skills to code in r, r shiny, and microsoft azure machine learning."
    },
    {
        "text": "as it may have come to your attention as well, the job requirements vary across the different roles that we have seen so far."
    },
    {
        "text": "thus, how you prepare for an interview varies widely depending on the job role."
    },
    {
        "text": "in the next chapter, we\u2019ll explore how you can efficiently identify what to prep for!"
    },
    {
        "text": "5 \u201clinkedin: 2020 emerging jobs report,\u201d linkedin, accessed may 16, 2020."
    },
    {
        "text": "6 thomas h. davenport and d.j."
    },
    {
        "text": "patil, \u201cdata scientist: the sexiest job of the 21st century,\u201d harvard business review, october 2012."
    },
    {
        "text": "what do you want to do?"
    },
    {
        "text": "with a strong handle on the different roles available in the market, let\u2019s move on to you!"
    },
    {
        "text": "this book will help you prepare for interviews for one of the three roles mentioned in the previous chapter."
    },
    {
        "text": "we will discuss the popular questions observed in data science-related interviews and provide sample answers to each of the questions."
    },
    {
        "text": "additionally, i will help you formulate a framework you can use to answer questions not seen in this book to differentiate yourself from other candidates."
    },
    {
        "text": "the book spans many different areas of data science, covering machine learning, deep learning, statistical knowledge, and technology/programming questions."
    },
    {
        "text": "we will also strategize how to tackle online coding tests and take- home exams and dive into some case studies to ensure you are well prepped for any case interviews rounds you may have."
    },
    {
        "text": "to be clear, this book will not tackle interview strategies for data engineer and data architect roles as those focus more on developing and maintaining databases and large-scale processing systems, which is out of scope for this book."
    },
    {
        "text": "to help you prepare for the different areas in data science, i constructed the visual below to serve as a guideline."
    },
    {
        "text": "to the left, i have listed the key areas to prepare for and then drilled down into the specific skill sets in each."
    },
    {
        "text": "to the right, i have laid out the three key job role groupings we discussed and a heat map indicating how the importance of different skill sets varies across roles."
    },
    {
        "text": "data science skill sets by roles you can use this as a starting point to evaluate what skills you have right now versus what skills you need to fit the bill of the role you want to be in."
    },
    {
        "text": "this gap analysis will help to identify the key areas you need to extensively prepare for and what areas may need just a refresher."
    },
    {
        "text": "doing the exercise above will help you immensely if you\u2019re looking to move from one job role to the other; for example, if you want to move from a business analytics type of role to a machine learning engineer role."
    },
    {
        "text": "additionally, you can utilize the information in the grid above to narrow down the specific areas you need to focus on before your interview."
    },
    {
        "text": "each of the following chapters in this book will discuss the skills sets listed above and will guide you on how you can ace the different rounds in a data science interview."
    },
    {
        "text": "part 2 cracking the technical rounds"
    },
    {
        "text": "modeling and machine learning questions if you see any of the following bullet points as part of a job description, then the insights in this chapter are going to be key for your interview: develop and validate data-driven experiments, forecasting algorithms, and machine learning models."
    },
    {
        "text": "engage with statistical methods such as forecasting, time series, hypothesis testing, regression, classification, and clustering."
    },
    {
        "text": "employ extensive knowledge in data mining, predictive modeling, machine learning, and text analytics."
    },
    {
        "text": "an interview for a job role that involves the use of machine learning algorithms and predictive modeling techniques will test you on your knowledge in these areas."
    },
    {
        "text": "expect the interview to get into the weeds of the algorithms you have worked on in the past."
    },
    {
        "text": "in this chapter, we will walk through a few questions within the realm of modeling and machine learning."
    },
    {
        "text": "please note this list isn\u2019t exhaustive, but it does offer a flavor of the kinds of interview questions one can expect."
    },
    {
        "text": "i have added quite a bit of detail to the answers in this chapter so you can use this book to recap some of the key concepts before an interview."
    },
    {
        "text": "note that you may not be required to go into that level of detail unless probed by your interviewer, but being prepared is always good!"
    },
    {
        "text": "practice question #1\u2014overfitting in predictive models interviewer: how can you avoid overfitting in predictive models?"
    },
    {
        "text": "before we dive into the answer, let us look at why this is important."
    },
    {
        "text": "why is this important?"
    },
    {
        "text": "when we build a predictive model, one of the key things to look at is the prediction error we obtain from the model built."
    },
    {
        "text": "prediction error in a regression model is how well your model can predict the response variable."
    },
    {
        "text": "for classification models, it is a measure of how well the model classifies to the correct category."
    },
    {
        "text": "prediction error can be explained by bias and variance errors."
    },
    {
        "text": "bias essentially is the difference between the forecast and the actual that we are trying to predict."
    },
    {
        "text": "variance is the variability of the forecasted value and gives an estimate of the spread of the model data."
    },
    {
        "text": "to understand bias and variance better, let us visualize them in the form of targets on a dart board."
    },
    {
        "text": "for example, high-variance, low-bias would be hitting darts on a dartboard at varied spots but far away from the center, whereas low-variance, high-bias would be hitting the darts in close proximity but far away from the center target."
    },
    {
        "text": "bias-variance trade-off"
    },
    {
        "text": "underfitting in supervised machine learning algorithms happens when a model has high-bias, low-variance."
    },
    {
        "text": "hence, these models are not able to capture the underlying trend in the data."
    },
    {
        "text": "this could happen due to insufficient data being available to build the model or too few features being included in the model."
    },
    {
        "text": "overfitting in supervised machine learning algorithms happens when a model has low-bias, high-variance."
    },
    {
        "text": "these models fit the train data too well but aren\u2019t able to predict with a high accuracy on the test data."
    },
    {
        "text": "overfitting occurs when the model fits the noise rather than the actual trend in the data, making it incapable of predicting with good accuracy on data it hasn\u2019t seen before."
    },
    {
        "text": "these models tend to react significantly to minor fluctuations in data leading to poor accuracy."
    },
    {
        "text": "to build a good model, we need a balance between the bias-variance trade- off."
    },
    {
        "text": "now that we see why these concepts are important, let\u2019s attempt to answer the original question."
    },
    {
        "text": "candidate: a model is said to overfit when it describes the noise in the data rather than the underlying relationship."
    },
    {
        "text": "based on my experience, overfitting can be avoided in the following ways: reduce model complexity: overfitting can be caused by having too many features in the model, which makes it more complex than required."
    },
    {
        "text": "cutting down on the number of features by including only those that truly influence the model\u2019s prediction can prevent overfitting."
    },
    {
        "text": "a simple approach to do this is to run a forward stepwise regression."
    },
    {
        "text": "in this method, a predictor will be added to the model which has the smallest p-value, and this will be done across multiple iterations until the stopping criterion is met."
    },
    {
        "text": "albeit an easy solution, this approach could miss the \u201cbest\u201d model."
    },
    {
        "text": "regularization: when making use of regularization techniques, we shrink/regularize the coefficient estimates toward zero."
    },
    {
        "text": "an added benefit of this technique is that it avoids modeling of any noise in the data which will prevent overfitting."
    },
    {
        "text": "ridge and lasso techniques can be used to reduce the number of predictors used in the model when you have a scenario as"
    },
    {
        "text": "described in the question."
    },
    {
        "text": "interviewer: yes, those two approaches make sense."
    },
    {
        "text": "can you explain a little more about how ridge and lasso regression work?"
    },
    {
        "text": "candidate: sure, i have used regularized regression in a few of my projects in the past."
    },
    {
        "text": "at a high level, in ridge regression, the loss function or the residual sum of square errors is minimized by adding a shrinkage quantity."
    },
    {
        "text": "ridge regression makes use of lamda, which acts as a tuning parameter for the model."
    },
    {
        "text": "as the value of lamda increases, the coefficient estimates tend toward zero."
    },
    {
        "text": "lasso is another regularization method and has the capability of \u201cselecting\u201d variables by penalizing the high value coefficients."
    },
    {
        "text": "lasso in comparison to ridge will shrink the coefficient values to a zero-value, allowing the model to select a small number of variables as the final predictors in the model, whereas ridge regression will shrink them close to zero but not necessarily make them zero."
    },
    {
        "text": "in other words, the ridge regression model will include almost all predictors whereas lasso will perform feature selection."
    },
    {
        "text": "interviewer: that\u2019s great."
    },
    {
        "text": "are there any other ways you can think of using which you can prevent overfitting in models?"
    },
    {
        "text": "candidate: yes, cross-validation is another preventive measure against overfitting and an important one at that."
    },
    {
        "text": "using cross-validation, you can generate multiple smaller train-test splits."
    },
    {
        "text": "for example, in k-fold cross- validation, you will use k-1 folds to train the model while the remaining fold (or holdout fold) will be used as a test set."
    },
    {
        "text": "when training on k-1 folds, cross- validation can be used to tune the parameters."
    },
    {
        "text": "the rationale behind using cross-validation is that we are varying what we train on and what we test on."
    },
    {
        "text": "by generalizing well, we can avoid potential overfitting."
    },
    {
        "text": "interviewer: that sounds good."
    },
    {
        "text": "thank you very much."
    },
    {
        "text": "differentiator: while this sufficiently answers the interviewer\u2019s question, a good way to distinguish yourself from the other candidates is to layer in an example of when you have dealt with such a scenario in the past."
    },
    {
        "text": "the key when giving an example is to keep it concise to demonstrate real-life experience."
    },
    {
        "text": "if the interviewer wishes to go into details, they may ask you further questions on the topic."
    },
    {
        "text": "extra questions for practice on this topic: what is the difference between forward stepwise and backward stepwise regression?"
    },
    {
        "text": "why does lasso tend to shrink estimates to zero whereas ridge shrinks them close to zero but not zero?"
    },
    {
        "text": "practice question #2\u2014determine number of clusters in k-means interviewer: how will you define the number of clusters in a clustering algorithm?"
    },
    {
        "text": "why is this important?"
    },
    {
        "text": "clustering is a technique that\u2019s used to group together objects with similar characteristics."
    },
    {
        "text": "in their simplest form, clusters are sets of data points that share similar attributes, and clustering algorithms are the methods that group these data points into different clusters based on their similarities."
    },
    {
        "text": "you\u2019ll see clustering algorithms used for disease classification in medical science, but you\u2019ll also see them used for customer classification in marketing research and for environmental health risk assessment in environmental engineering.7 the purpose of clustering and classification algorithms is to make sense of and extract value from large sets of structured and unstructured data."
    },
    {
        "text": "if you\u2019re working with huge volumes of unstructured data, it only makes sense to try to partition the data into some sort of logical groupings before attempting to analyze it.8 before beginning to answer this question, let\u2019s understand how clustering algorithms work."
    },
    {
        "text": "how does this work?"
    },
    {
        "text": "one of the popular algorithms used for clustering is the k-means algorithm."
    },
    {
        "text": "k-means uses distance as a measure of similarity."
    },
    {
        "text": "let\u2019s say you have a data set with two columns, column a and column b."
    },
    {
        "text": "now, you would like to cluster this data set based on similarities observed in the two columns."
    },
    {
        "text": "and you would like to use k-means algorithm to create the clusters."
    },
    {
        "text": "k-means needs you to specify the number of clusters you want at the onset."
    },
    {
        "text": "suppose for this example, you think three would be a good start."
    },
    {
        "text": "once you have set this hyperparameter, here\u2019s how the algorithm would then work: the algorithm will randomly assign any three points as the cluster centers."
    },
    {
        "text": "then, it will compute the distance between each observation and the cluster centers."
    },
    {
        "text": "after this, it will assign each observation to a cluster that is closest to it in value."
    },
    {
        "text": "it will then calculate the mean of the new clusters and keep doing this until there is no change in the clusters."
    },
    {
        "text": "the clusters, for our example, can be visualized as below:"
    },
    {
        "text": "scatterplot of variable a, b let\u2019s now dive into the specifics of the answer for the question asked by the interviewer."
    },
    {
        "text": "candidate: algorithms like k-means that are used popularly for clustering need the user to input the number of clusters to be built."
    },
    {
        "text": "given this requirement, you must determine the optimal number of clusters to be generated."
    },
    {
        "text": "a commonly used method to determine this is using the elbow curve."
    },
    {
        "text": "interviewer: how do you recommend using the elbow curve to determine the number of clusters?"
    },
    {
        "text": "candidate: to answer this, let me recap a bit on how k-means work."
    },
    {
        "text": "k-means work toward reducing the intra-cluster variation; in other words, the within- cluster sum of square (wss) is minimized."
    },
    {
        "text": "this wss statistic is plotted"
    },
    {
        "text": "against the number of clusters, forming the elbow curve."
    },
    {
        "text": "typically, one can see a huge drop in the wss after x number of clusters."
    },
    {
        "text": "the point where the drop is observed is to be taken as the optimal number."
    },
    {
        "text": "for reference: the graph below shows a sample elbow curve that plots the wss* metric against the number of clusters."
    },
    {
        "text": "for this particular example, you can see that the graph changes drastically at cluster size = 3. the curve becomes linear in shape, and that\u2019s the optimal point in the curve that determines the number of clusters to be used for that data set."
    },
    {
        "text": "*wss metric: average of the squared distances from the cluster centers of the respective clusters."
    },
    {
        "text": "typically, the euclidean distance metric is used."
    },
    {
        "text": "elbow curve differentiator: similar to the first question in this chapter, i would"
    },
    {
        "text": "recommend layering in a short example of when you have done this in the past."
    },
    {
        "text": "for this question, you can talk about a clustering project you worked on and how many segments you ended up with."
    },
    {
        "text": "while looking at the elbow curve to determine the number of clusters is a good way to go about it, a validation check toward the end is to see whether the clusters formed are intuitive or not."
    },
    {
        "text": "you can tie them back to the problem you\u2019re trying to solve and see if the clusters formed are sufficient to answer the business problem."
    },
    {
        "text": "depending on the objective for clustering, you may find yourself iterating to find the optimal number of clusters that answers the business question sufficiently and is statistically sound."
    },
    {
        "text": "extra questions for practice on this topic: what are some other clustering techniques?"
    },
    {
        "text": "e.g., hierarchical clustering, density-based clustering."
    },
    {
        "text": "which clustering algorithm is typically sensitive to outliers?"
    },
    {
        "text": "can clustering be used to improve the accuracy of a linear regression model?"
    },
    {
        "text": "if so, how?"
    },
    {
        "text": "can categorical variables be used in k-means clustering?"
    },
    {
        "text": "if there is mix of categorical and continuous variables, which clustering technique would you use?"
    },
    {
        "text": "practice question #3\u2014favorite algorithm interviewer: what is your favorite algorithm and why?"
    },
    {
        "text": "why is this important?"
    },
    {
        "text": "in a conversation with andy fox, a senior director at opex analytics, i asked if he had a go-to question when he conducts interviews for data scientists."
    },
    {
        "text": "and this is the question andy shared with me."
    },
    {
        "text": "this is an interesting one because it\u2019s open-ended in nature and allows the candidate to lead the interviewer to an answer they have a good deal of knowledge about, essentially allowing them to show off their modeling skills!"
    },
    {
        "text": "on the other hand, it allows the interviewer to test the candidate\u2019s depth of knowledge in a particular area."
    },
    {
        "text": "pro tip: for a broad question such as this, you should frame your answer so it"
    },
    {
        "text": "covers a few key aspects."
    },
    {
        "text": "here is an outline as a reference point: my favorite algorithm is... this model can be used for...[list use cases you know for this model, e.g., classification or regression] this algorithm works as follows...[give a brief overview of how this model works behind the scenes] this is my favorite algorithm because...[list a couple of reasons why you think this model is good] i used this algorithm to...[describe a project where and how you used it] for practice, let\u2019s walk through an example of how this question can be answered."
    },
    {
        "text": "for simplicity and ease of understanding, let\u2019s use a popular model."
    },
    {
        "text": "candidate: my favorite algorithm is random forest."
    },
    {
        "text": "it can be used for classification and regression use cases."
    },
    {
        "text": "random forest consists of a large number of decision trees and works as an ensemble technique."
    },
    {
        "text": "random forests works on the principle of bagging, wherein each decision tree is built on a sample of the training data set with replacement."
    },
    {
        "text": "the results from these multiple decision trees are then aggregated to come up with the final forecast."
    },
    {
        "text": "for the purposes of classification, the mode of all the predictions is used, and for regression, the mean of all predictions is deemed as the final output."
    },
    {
        "text": "this is my favorite algorithm for a few reasons: random forests work well with both categorical and numerical data."
    },
    {
        "text": "no scaling or transformation of variables is usually necessary."
    },
    {
        "text": "random forests implicitly perform feature selection and generate uncorrelated decision trees."
    },
    {
        "text": "it does this by choosing a random set of features to build each decision tree."
    },
    {
        "text": "this also makes it a great model when you have to work with a high number of features in the data."
    },
    {
        "text": "random forests are not influenced by outliers to a fair degree."
    },
    {
        "text": "it does this by binning the variables."
    },
    {
        "text": "random forests can handle linear and non-linear relationships well."
    },
    {
        "text": "random forests generally provide a high accuracy and balance the bias- variance trade off well."
    },
    {
        "text": "since the model\u2019s principle is to average the results across the multiple decision trees it builds, it averages the variance as well differentiator: this answer covers all main aspects of the algorithm that you like and leaves room for more conversation on this topic."
    },
    {
        "text": "a good differentiator for such a question would be to follow up with two more points: describe two to three drawbacks of this algorithm and describe a situation where you wouldn\u2019t recommend using it."
    },
    {
        "text": "give a quick overview on an algorithm that performs better than the one you chose to describe, allowing the interviewer to know that you are researching and exploring further."
    },
    {
        "text": "for our example, you can follow up and conclude your answer in the following way: while random forests are great in a number of applications, there are certain places where they may not be an ideal choice."
    },
    {
        "text": "here are a couple reasons why this could be so: \u2013 random forests aren\u2019t easily interpretable."
    },
    {
        "text": "although they provide feature importance, they do not provide complete visibility into the coefficients like a linear regression does."
    },
    {
        "text": "\u2013 random forests can be computationally intensive for large datasets."
    },
    {
        "text": "another algorithm that i have been working on recently that i quite like is xgboost."
    },
    {
        "text": "xgboost improves upon the capabilities that random forest has by making use of the gradient descent framework."
    },
    {
        "text": "it also has the ability to build trees in parallel and optimizes hardware as it does so."
    },
    {
        "text": "xgboost has the in-built capability to penalize complex models by using regularization techniques."
    },
    {
        "text": "it also comes with in-built cross validation that can be used to determine the number of boosting iterations required in a run."
    },
    {
        "text": "additionally, choice of the algorithm largely depends on its use case and data availability."
    },
    {
        "text": "while the question we discussed above assumes you can answer"
    },
    {
        "text": "for any use case without data constraints, feel free to ask your interviewer if they are looking for a specific use case for you to address."
    },
    {
        "text": "in the sample answer above, we focused on a supervised learning algorithm, feel free to use an unsupervised learning algorithm if your expertise lies in that area."
    },
    {
        "text": "extra questions for practice on this topic: how do models like random forest determine feature importance?"
    },
    {
        "text": "what are the key hyper parameters to specify when building a random forest?"
    },
    {
        "text": "how can overfitting be avoided in random forests?"
    },
    {
        "text": "what is your favorite deep learning algorithm?"
    },
    {
        "text": "if you have worked on tree-based models in the past, expect the interviewer to go into detail about how they work, to suggest advantages and disadvantages of using them, and to discuss use cases of where you have used them in the past."
    },
    {
        "text": "for a handy reference, here\u2019s a cheat sheet i like to refer to when revising my knowledge of tree-based models!9"
    },
    {
        "text": "evolution of tree-based models practice question #4\u2014evaluate performance of a predictive model interviewer: how do you evaluate performance of a predictive model?"
    },
    {
        "text": "why is this important?"
    },
    {
        "text": "once you have built a predictive model, you need a way to evaluate whether it is performing at the level you expect."
    },
    {
        "text": "the success criteria of a predictive model are driven by what the model is going to be used for."
    },
    {
        "text": "for example, if the goal of the business is to forecast demand for a certain product, then metrics relating to accuracy can be used to evaluate performance."
    },
    {
        "text": "however, at the same time, certain metrics can be deceiving."
    },
    {
        "text": "for example, let\u2019s say you have a model that detects fraud, and fraud is expected to happen only 1 percent of the time."
    },
    {
        "text": "such a model may have a high accuracy, say up to 99 percent, but the model may fail to detect any fraud cases at all."
    },
    {
        "text": "in this scenario, looking at the overall accuracy metric in an isolated fashion will not be the correct choice."
    },
    {
        "text": "for this particular case, it may be useful to look at the true positive rate and false positive rate produced by the model."
    },
    {
        "text": "choosing the correct set of metrics to evaluate the model against is key."
    },
    {
        "text": "for this question, let\u2019s look at the metrics available for the supervised learning models."
    },
    {
        "text": "quick recap: supervised learning is where the data is \u201clabeled\u201d when training the model."
    },
    {
        "text": "examples of supervised learning are classification and regression models."
    },
    {
        "text": "unsupervised learning is where the data is not \u201clabeled\u201d or the output values are not known."
    },
    {
        "text": "examples of unsupervised learning are clustering and principal component analysis."
    },
    {
        "text": "candidate: to evaluate the success of a predictive model, we look at a few key metrics, and this differs by the type of the model, e.g., classification or regression."
    },
    {
        "text": "let\u2019s start with the metrics used for classification."
    },
    {
        "text": "classification: confusion matrix: a confusion matrix is popularly used to evaluate performance of classification models."
    },
    {
        "text": "i have used overall accuracy, sensitivity, and specificity metrics when i have built classification models in the past."
    },
    {
        "text": "for reference: here\u2019s a quick recap on the formulae used in the confusion matrix."
    },
    {
        "text": "overall accuracy: proportion of number of predictions that were correctly classified."
    },
    {
        "text": "positive predictive value or precision: proportion of positive cases that were correctly classified."
    },
    {
        "text": "negative predictive value: proportion of negative cases that were correctly classified."
    },
    {
        "text": "sensitivity or recall: proportion of actual positive cases that were correctly classified."
    },
    {
        "text": "specificity: proportion of actual negative cases that were correctly classified."
    },
    {
        "text": "interviewer: in what instances do you recommend using one metric over the other for classification models?"
    },
    {
        "text": "candidate: so, depending on the use case of the classification problem, one of these metrics will be more suited than the other."
    },
    {
        "text": "for example, a pharmaceutical company will be concerned with minimal incorrect positive diagnosis."
    },
    {
        "text": "hence, the metric to evaluate for this use case will be specificity (aiming for a high specificity value)."
    },
    {
        "text": "on the other hand, for a model that predicts loan default rates, the model should capture the slightest chance of a default, hence we need the model to be highly sensitive."
    },
    {
        "text": "confusion matrix cheat sheet cheat sheet: use this diagram to visually remember the different metrics."
    },
    {
        "text": "interviewer: thank you for that example."
    },
    {
        "text": "are there any other metrics you"
    },
    {
        "text": "look at for classification models?"
    },
    {
        "text": "candidate: yes, i have used f1 score and area under the roc curve as well in the past."
    },
    {
        "text": "f1 score: for a use case that requires a balance between precision and recall, the f1 score is used."
    },
    {
        "text": "f1 score is the harmonic mean of precision and recall values."
    },
    {
        "text": "it punishes extreme values more to keep the balance."
    },
    {
        "text": "area under the roc curve: the roc chart shows 1-specificity (or false positive rate) on the x-axis and sensitivity (or true positive rate) on the y- axis."
    },
    {
        "text": "area under the curve metric is often used to measure the quality of the classification model and visually shows the trade-off between sensitivity and specificity."
    },
    {
        "text": "if the model is good, the chart quickly climbs up in value on the y- axis."
    },
    {
        "text": "typically, a value between 0.5 and 1 for this metric is considered good."
    },
    {
        "text": "example of an roc curve candidate: that being said, multiple metrics can be used to evaluate a classification model."
    },
    {
        "text": "the choice should be made based on the end use case of the model."
    },
    {
        "text": "interviewer: that sounds good."
    },
    {
        "text": "can you now walk me through the metrics that can be used to evaluate the performance of a regression model?"
    },
    {
        "text": "candidate: often for regression models, i have used root mean squared error, mean absolute error, and r-square."
    },
    {
        "text": "interviewer: can you explain the difference between r-square and adj r- square metrics?"
    },
    {
        "text": "candidate: r-square may keep increasing when a greater number of features are added in the model even though the model isn\u2019t improving, whereas adj r-square will likely remain the same."
    },
    {
        "text": "adj r-square penalizes for adding more variables in the model, and adj r-square will always be less than or equal to r-square."
    },
    {
        "text": "for reference: if asked to go into details, here\u2019s a recap of these metrics."
    },
    {
        "text": "root mean squared error (rmse): rmse is a measure of how spread out the residuals are, where residuals are the difference between actuals and predicted."
    },
    {
        "text": "rmse penalizes the higher prediction errors more than the mae."
    },
    {
        "text": "mean absolute error (mae): mae is the average of the absolute difference between the predicted values and observed value."
    },
    {
        "text": "r-square/adjusted r-square: r-squared is a goodness of fit measure used for linear regression models."
    },
    {
        "text": "r-square and adjusted r-square give insight into how the independent variables explain the variability in the dependent variable."
    },
    {
        "text": "note: n is the total number of observations and k is the number of predictors."
    },
    {
        "text": "differentiator: while this answer expertly covers the different metrics that can be used to evaluate the model, a few other factors can be taken into consideration for an added differentiation."
    },
    {
        "text": "for a business scenario that values transparency in the model, you must check if the model is directionally correct."
    },
    {
        "text": "for example, when building a linear regression model, check whether the sign of the coefficients is directionally intuitive."
    },
    {
        "text": "check if the model is robust and ensure model is not overfitting."
    },
    {
        "text": "extra questions for practice: how will you deal with an imbalanced data set when building a predictive model?"
    },
    {
        "text": "what metrics will you evaluate for a classification model built on imbalanced data?"
    },
    {
        "text": "what metric will you look at to evaluate whether a model is overfitting?"
    },
    {
        "text": "what are the limitations of using r-square to evaluate model performance?"
    },
    {
        "text": "practice question #5\u2014determine parameter values in arima interviewer: how can you determine the parameter values in a time series arima model?"
    },
    {
        "text": "why is this important?"
    },
    {
        "text": "real-world applications of time series analysis are endless."
    },
    {
        "text": "accurate forecasting enables businesses to plan and execute better."
    },
    {
        "text": "for example, time series analysis can be used for stock market analysis, inventory projections, and economic forecasting, to name a few."
    },
    {
        "text": "before we jump into the details of time series modeling, let\u2019s understand the basics of time series data."
    },
    {
        "text": "time series data is essentially a set of observations arranged in a chronological order."
    },
    {
        "text": "this data can be primarily broken down into four main components: trend: the trend component of the time series data shows the general tendency of the data to increase or decrease with time."
    },
    {
        "text": "for example, prices of commodities such as gold have a tendency to increase over time."
    },
    {
        "text": "seasonality: any systematic and calendar-driven effects observed in the time series data make up the seasonal component."
    },
    {
        "text": "for example, turkey sales are expected to shoot up around thanksgiving."
    },
    {
        "text": "cyclicity: patterns that depict an upward or downward movement around a given trend is the cyclical component."
    },
    {
        "text": "for example, the stock markets have a tendency to cycle between highs and lows, but the duration of time between these fluctuations isn\u2019t known like it is in seasonality."
    },
    {
        "text": "randomness: this component of a time series is unpredictable and random."
    },
    {
        "text": "the random component of a time series is unlikely to be repeated."
    },
    {
        "text": "let\u2019s look at an example that shows different combinations of the above components."
    },
    {
        "text": "four examples of time series showing different patterns 1. the monthly housing sales (top left) show strong seasonality within each year, as well as some strong cyclic behavior with a period of about six to ten years."
    },
    {
        "text": "we can see no apparent trend in the data over this period."
    },
    {
        "text": "2. the us treasury bill contracts (top right) show results from the chicago market for one hundred consecutive trading days in 1981. here we see no seasonality, but an obvious downward trend."
    },
    {
        "text": "possibly, if we had a much longer series, we would see that this downward trend is actually part of a long cycle, but when viewed over only one hundred days it appears to be a trend."
    },
    {
        "text": "3. the australian quarterly electricity production (bottom left) shows a strong increasing trend with strong seasonality."
    },
    {
        "text": "we see no evidence of any cyclic behavior here."
    },
    {
        "text": "4. the daily change in the google closing stock price (bottom right) has no trend, seasonality, or cyclic behavior."
    },
    {
        "text": "we can see random fluctuations which do not appear to be very predictable and no strong patterns that would help"
    },
    {
        "text": "with developing a forecasting model.10 with a brief overview of what a time series data set consists of, we can jump into understanding arima models."
    },
    {
        "text": "arima stands for autoregressive integrated moving average and is used for time series analysis."
    },
    {
        "text": "arima models have three key parameters we need to tune when building the model: p: parameter p refers to the number of periods to lag for and corresponds to the autoregressive (ar) part of the arima model."
    },
    {
        "text": "a purely autoregressive model is essentially a linear regression where the dependent variables are p lagged variables."
    },
    {
        "text": "d: parameter d stands for differencing."
    },
    {
        "text": "data fed to an arima model is required to be stationary, i.e., a series without any trend or seasonality."
    },
    {
        "text": "to remove the trend/seasonality, the variables are differenced."
    },
    {
        "text": "d refers to the number of differencing that needs to be applied to the data to make it stationary."
    },
    {
        "text": "q: parameter q denotes the lag of the error component."
    },
    {
        "text": "the error component is the one that cannot be explained and is random at best."
    },
    {
        "text": "this corresponds to the moving average (ma) part of the arima model and is used to smooth out any random jumps observed in the data."
    },
    {
        "text": "the value of these parameters is decided depending on what is observed in the data."
    },
    {
        "text": "candidate: typically, an arima model consists of three key parameters (p, d, q)."
    },
    {
        "text": "the order of the autoregressive (ar) and moving average (ma) components of an arima model, or p and q respectively, can be identified by acf and pacf plots."
    },
    {
        "text": "interviewer: can you tell me a little more about the acf and pacf plots and how they can be used for determining the p and q values?"
    },
    {
        "text": "candidate: sure, acf is an auto-correlation plot that gives us the correlation between the predictor variable and its lagged values."
    },
    {
        "text": "pacf is a partial auto-correlation plot and finds correlation with the residuals."
    },
    {
        "text": "the partial autocorrelation at lag q is the correlation that results"
    },
    {
        "text": "after removing the effect of any correlations due to the terms at shorter lag.11 here\u2019s the idea behind using these plots: when the correlation is plotted against the lagged values (acf plot), one would expect the plot to tail off as the effect weakens."
    },
    {
        "text": "when tailing off is observed in an acf plot, we can say that an ar term is needed in the arima model and the value for the term ar term (p) can be determined at the point where we observe it to tail off."
    },
    {
        "text": "similarly, if we observe a tailing off in the pacf plot that plots the correlation of residuals against the lags, we can say that a moving average component is required in the model and the value of the parameter can be at the lag that it tails off."
    },
    {
        "text": "alternatively, you would see that the acf plot cuts off after a certain lag, indicating a moving average process the cuts off after a lag q. interviewer: got it, and how would you determine the value of parameter d?"
    },
    {
        "text": "candidate: parameter d is used to indicate the number of differencing to be used to make the time series data stationary."
    },
    {
        "text": "since the data is said to be stationary when it does not have any trend or seasonality component (i.e., the mean and the variance are constant), plots of the differenced variables can be inspected to find out at what value stationarity is achieved."
    },
    {
        "text": "interviewer: that makes sense, thank you."
    },
    {
        "text": "time series models are widely used."
    },
    {
        "text": "to help you prepare well for interviews, here are some more details about time series models."
    },
    {
        "text": "cheat sheet: here\u2019s a cheat sheet for how to use acf and pacf values to determine p, q parameters."
    },
    {
        "text": "determine p and q using acf and pacf plots quick recap: here are some examples of acf and pacf plots for quarterly percentage change in us consumption expenditure data:"
    },
    {
        "text": "quarterly percentage change in us consumption expenditure acf of quarterly percentage change in us consumption"
    },
    {
        "text": "pacf of quarterly percentage change in us consumption in the plots above, we see three spikes in the acf followed by an almost significant spike at lag 4. in the pacf, we see three significant spikes and then no significant spikes thereafter (apart from one just outside the bounds at lag twenty-two)."
    },
    {
        "text": "we can ignore one significant spike in each plot if it is just outside the limits, and not in the first few lags."
    },
    {
        "text": "after all, the probability of a spike being significant by chance is about one in twenty, and we are plotting twenty-two spikes in each plot."
    },
    {
        "text": "the pattern in the first three spikes is what we would expect from an arima (3,0,0), as the pacf tends to decrease."
    },
    {
        "text": "so, in this case, the acf and pacf lead us to think an arima (3,0,0) model might be appropriate.12 extra questions for practice on this topic: why should a time series be transformed into a stationary series before building an arima model?"
    },
    {
        "text": "how do you test for stationarity of time series data?"
    },
    {
        "text": "can you explain how arima and arimax models are different?"
    },
    {
        "text": "you can expect to encounter the types of questions we covered in this chapter in a data science technical screen."
    },
    {
        "text": "typically, in these screens, the company wants to evaluate you on fundamental data science skills before moving you on to the next rounds."
    },
    {
        "text": "to adequately prepare for such questions, go over the basic machine learning techniques and ensure your conceptual understanding of them is sound."
    },
    {
        "text": "once you have done that, prepare extensively on the techniques you have used in past projects so you are well"
    },
    {
        "text": "prepped for situations in which the interviewer may want to do a deep dive."
    },
    {
        "text": "7 \u201cthe importance of clustering and classification in data science,\" dummies.com, accessed may 17, 2020."
    },
    {
        "text": "8 ibid."
    },
    {
        "text": "9 rob j. hyndman and george athanasopoulos, forecasting: principles and practice, 2nd edition (melbourne: otexts, 2018)."
    },
    {
        "text": "10 inspired from: vishal morde, \u201cxgboost algorithm: long may she reign!,\u201d medium.com, accessed may 20, 2020."
    },
    {
        "text": "11 andrew v. metcalfe and paul s.p."
    },
    {
        "text": "cowpertwait, introductory time series with r (new york: springer, 2009), 81."
    },
    {
        "text": "12 rob j. hyndman and george athanasopoulos, forecasting: principles and practice, 2nd edition (melbourne: otexts, 2018)."
    },
    {
        "text": "probability, statistics, and experimental design probability and statistics form the foundation of any data science work."
    },
    {
        "text": "by and large, any analysis that you do will have these two topics at its base and for this reason, the probability that an interviewer may test your understanding of these subjects is high (pun intended)."
    },
    {
        "text": "think of these topics as prerequisites for data science."
    },
    {
        "text": "to showcase your understanding of the fundamentals, you must cover the basics before an interview."
    },
    {
        "text": "in this chapter, i will walk you through a few key concepts and demonstrate how an interviewer can probe into your comprehension of these subjects."
    },
    {
        "text": "this chapter is divided into three sections: 1. probability 2. statistics 3. experimental design probability our goal for this section is to recap key concepts in probability and work through some practice problems so you have in-depth clarity on the fundamentals."
    },
    {
        "text": "while the subject of probability in itself is very vast and worthy of its own book, in this chapter we will look at a few concepts that will act as a refresher as you prepare for your interviews."
    },
    {
        "text": "let\u2019s dive right in."
    },
    {
        "text": "what is probability?"
    },
    {
        "text": "probability is the likelihood of the occurrence of an event."
    },
    {
        "text": "an event can be anything, such as drawing a card from a deck or"
    },
    {
        "text": "tossing a coin."
    },
    {
        "text": "there are varying degrees of probability of whether an event can occur."
    },
    {
        "text": "if an event cannot occur at all, its probability is zero."
    },
    {
        "text": "if an event is certain to occur, its probability is one."
    },
    {
        "text": "hence, the possibility of an event occurrence is always between zero and one."
    },
    {
        "text": "the probability of an event is the number of ways the event can occur divided by the total number of possible outcomes."
    },
    {
        "text": "e.g., probability of getting a head on the toss of a coin = 1/2 compound events: when we use the term compound event in math, we are referring to the probability of two or more events happening at the same time.13 compound probability is a mathematical term relating to the likeliness of two independent events occurring."
    },
    {
        "text": "compound probability is equal to the probability of the first event multiplied by the probability of the second event.14 p(a or b) is the probability of the occurrence of at least one of the events."
    },
    {
        "text": "p(a and b) is the probability of the occurrence of both a and b at the same time."
    },
    {
        "text": "mutually exclusive events: when two events cannot occur at the same time, they are called mutually exclusive events."
    },
    {
        "text": "for mutually exclusive events a and b: independent events: an event is said to be independent when the outcome of it is not affected by the outcome of any other event."
    },
    {
        "text": "for example, if you toss a fair coin, the outcome of the first toss does not affect the outcome of the second toss."
    },
    {
        "text": "practice questions 1. what is the probability of getting a 1 or a 6 on the roll of a die?"
    },
    {
        "text": "p(1 or 6) = p(1) + p(6) \u2013 p(1 and 6) = 1/6 + 1/6 \u2013 0 = 1/3."
    },
    {
        "text": "2. what is the probability of getting a black card or a king from a deck of cards?"
    },
    {
        "text": "p(black card or king) = p(black card) + p(king) - p(black card and king) p(black card) = 26/52 p(king) = 4/52 p(black card and king) = 2/52 p(black card or king) = (26/52) + (4/52) - (2/52) = 28/52 = 7/13 3. a box contains 3 black, 2 blue, and 5 red balls."
    },
    {
        "text": "what is the probability of picking 2 black and 1 red ball with replacement?"
    },
    {
        "text": "hint: since the balls are picked with replacement, the event of picking a single ball is an independent event."
    },
    {
        "text": "p(2 black and 1 red) = (3/10) *( 3/10) * (5/10) = 9/200 let\u2019s now look at conditional probability."
    },
    {
        "text": "conditional probability: conditional probability is used when you have to calculate the probability of an event given another event has occurred.15 conditional probability is often denoted as p(a|b), read as p(a given b)."
    },
    {
        "text": "the formula for conditional probability is: 16 practice questions 4. a math teacher gave her class two tests."
    },
    {
        "text": "25 percent of the class passed both tests and 42 percent of the class passed the first test."
    },
    {
        "text": "what is the probability that of those who passed the first test also passed the second test?17 p(second | first) = p(first and second) / p(first) = 0.25/0.42 = 0.6"
    },
    {
        "text": "5. in a group of 100 sports car buyers, 40 bought alarm systems, 30 purchased bucket seats, and 20 purchased an alarm system and bucket seats."
    },
    {
        "text": "if a car buyer chosen at random bought an alarm system, what is the probability they also bought bucket seats?"
    },
    {
        "text": "18 consider b as the event of buying bucket seats."
    },
    {
        "text": "consider a as the event of buying alarm systems."
    },
    {
        "text": "p(b|a) = p(a\u2229b) / p(a) = 0.2 / 0.4 = 0.5. pro tip: for questions like these, make use of a venn diagram to quickly visualize the numbers."
    },
    {
        "text": "this approach is very useful when you\u2019re asked a question that involves the intersection of three events."
    },
    {
        "text": "venn diagrams help simplify the question and lead to an answer faster."
    },
    {
        "text": "venn diagram for alarm system and bucket seats let us now look at bayes\u2019 theorem, which is pivotal in probability theory and statistics."
    },
    {
        "text": "bayes: bayes\u2019 theorem is central to many machine learning techniques today."
    },
    {
        "text": "for an interview where you are tested on probability, it is highly likely you may be asked a question related to bayes."
    },
    {
        "text": "let\u2019s say we are trying to find out the probability of being asked an interview question based on bayes."
    },
    {
        "text": "for this, you have additional evidence that the interview process will consist of a dedicated round on the topic of probability."
    },
    {
        "text": "before we jump into the actual calculation for our example, let\u2019s look at how bayes\u2019 rule is typically depicted."
    },
    {
        "text": "a: the event we want the probability of b: the evidence that a is related in some way p(a|b) is called the posterior."
    },
    {
        "text": "in our example, this would be the \u201cprobability of being asked a bayes question given that the interview process contains a dedicated round on the topic of probability.\u201d p(b|a) is called the likelihood."
    },
    {
        "text": "in our example, this would be the \u201cprobability of having a dedicated interview round on the topic of probability given that there was an interview question on bayes.\u201d p(a) is called the prior."
    },
    {
        "text": "in our example, this would be the \u201cprobability of being asked a bayes interview question.\u201d p(b) is called the marginal likelihood."
    },
    {
        "text": "in our example, this would be the \u201cprobability of having a dedicated interview round on the topic of probability.\u201d let us now plug in some numbers so we can use the equation to come to our answer."
    },
    {
        "text": "p(being asked a bayes interview question) = 0.1 p(having a dedicated interview round on the topic of probability) = 0.4 p(having a dedicated interview round on the topic of probability given that there was an interview question on bayes) = 0.6 therefore, p(being asked a bayes question given that the interview process contains a dedicated round on the topic of probability) = (0.6*0.1)/(0.4) = 3/20 using bayes theorem, we are able to use more information to update our probabilities to get a better estimate."
    },
    {
        "text": "solving problems using probability trees and tables: probability trees are an"
    },
    {
        "text": "easy way to visualize a probability problem and an excellent tool to use during your interview."
    },
    {
        "text": "they allow you to show your thought process to your interviewer on paper and brings them along on the journey when you\u2019re solving the problem they\u2019ve asked."
    },
    {
        "text": "mit\u2019s introduction to probability and statistics class has a very good example that showcases the use of trees and tables."
    },
    {
        "text": "let\u2019s look at it here."
    },
    {
        "text": "practice question 6. consider a routine screening test for a disease."
    },
    {
        "text": "suppose the frequency of the disease in the population (base rate) is 0.5 percent."
    },
    {
        "text": "the test is highly accurate with a 5 percent false positive rate and a 10 percent false negative rate."
    },
    {
        "text": "you take the test and it comes back positive."
    },
    {
        "text": "what is the probability that you have the disease?"
    },
    {
        "text": "answer: we will do the computation three times: using trees, tables, and symbols."
    },
    {
        "text": "we\u2019ll use the following notation for the relevant events: d+ = you have the disease d\u2212 = you do not have the disease t+ = you tested positive t\u2212 = you tested negative we are given p(d+) = .005 and therefore, p(d\u2212) = .995. the false positive and false negative rates are (by definition) conditional probabilities."
    },
    {
        "text": "p(false positive) = p(t + |d\u2212) = .05 and p(false negative) = p(t \u2212 |d+) = .1. the complementary probabilities are known as the true negative and true positive rates: p(t \u2212 |d\u2212) = 1 \u2212 p(t + |d\u2212) = .95 and p(t + |d+) = 1 \u2212 p(t \u2212 |d+) = .9. trees: all of these probabilities can be displayed quite nicely in a tree."
    },
    {
        "text": "probability tree"
    },
    {
        "text": "the question asks for the probability that you have the disease given that you tested positive; i.e., what is the value of p(d+|t+)?"
    },
    {
        "text": "we aren\u2019t given this value, but we do know p(t +|d+), so we can use bayes\u2019 theorem."
    },
    {
        "text": "the two probabilities in the numerator are given."
    },
    {
        "text": "we compute the denominator p(t+) using the law of total probability."
    },
    {
        "text": "using the tree, we sum the probabilities for each of the nodes marked t+."
    },
    {
        "text": "thus, tables: another trick that is useful for computing probabilities is to make a table."
    },
    {
        "text": "let\u2019s redo the previous example using a table built with 10,000 total people divided according to the probabilities in this example."
    },
    {
        "text": "we construct the table as follows: pick a number, say 10,000 people, and place it as the grand total in the lower right."
    },
    {
        "text": "using p(d+) = .005, we compute that 50 out of the 10,000 people are sick (d+)."
    },
    {
        "text": "likewise, 9,950 people are healthy (d\u2212)."
    },
    {
        "text": "at this point the table looks like: using p(t +|d+) = .9, we can compute that the number of sick people who tested positive as 90 percent of 50 or 45. the other entries are similar."
    },
    {
        "text": "at this point the table looks like the table below on the left."
    },
    {
        "text": "finally, we sum the t+ and t\u2212 rows to get the completed table on the right."
    },
    {
        "text": "using the complete table, we can compute, symbols: for completeness, we show how the solution looks when written out directly in symbols.19 before we move on to the next section of statistics, let\u2019s practice another question that is a bit conversational but has a flavor of probability."
    },
    {
        "text": "interviewers often tend to embed technical questions within a case-type problem to get a sense of your thought process and overall problem-solving approach."
    },
    {
        "text": "practice question 7. interviewer: let\u2019s say you walk into a fair and see a game with the following instructions: there are six closed boxes and at any given time only two of them have a toy inside it."
    },
    {
        "text": "you can ask to open any box by paying $5 for each turn."
    },
    {
        "text": "if the box you open has the toy in it, you win $10."
    },
    {
        "text": "each time you open the box, the game will be reset."
    },
    {
        "text": "will you play this game?"
    },
    {
        "text": "candidate: hmm, can i ask a clarifying question before i continue?"
    },
    {
        "text": "interviewer: sure."
    },
    {
        "text": "candidate: is there a limit on how many times i can ask to open a box?"
    },
    {
        "text": "interviewer: no, as long as you\u2019re paying the $5 fee for each turn, you can play an unlimited number of times."
    },
    {
        "text": "candidate: okay, so if i think through this, at any time there are two boxes out of six that have a toy inside it."
    },
    {
        "text": "hence, the probability of getting the toy is 2 by 6 or 33 percent."
    },
    {
        "text": "and the return on my investment of $5 if i win is $10."
    },
    {
        "text": "essentially, my return is two times that of my investment."
    },
    {
        "text": "on the other hand, the probability that i win is one to three."
    },
    {
        "text": "my risk is greater than the return on my investment, so this does not look favorable to me."
    },
    {
        "text": "given this reason, i will not play."
    },
    {
        "text": "interviewer: okay, that\u2019s fair."
    },
    {
        "text": "what amount if offered as the prize money will you be willing to pay?"
    },
    {
        "text": "candidate: if my return is greater than or the same as my risk, i will be willing to play."
    },
    {
        "text": "so, in this scenario, if my investment is 33 percent of the prize money offered, i will play."
    },
    {
        "text": "given that the cost to open a box is $5, if i am offered $15 as the prize money, i will be game to play as my risk and return will break even at those values."
    },
    {
        "text": "pro tip: while the interviewer is looking for the right numeric answer to their question, their main intention of asking probability-type questions is to test your knowledge of the fundamentals."
    },
    {
        "text": "so always make sure to explain your thought process as you solve the problem as well as any considerations or assumptions you have taken into account as you derive the final answer."
    },
    {
        "text": "you might be tempted to solve the question quickly and showcase your quick arithmetic abilities, but always remember to balance it with explaining the rationale behind it."
    },
    {
        "text": "the \u201chow\u201d and \u201cwhy\u201d is always as important as the \u201cwhat.\u201d statistics in my experience of going through the data science interview process, i have often encountered a statistics-related question in some shape or form during the interview process."
    },
    {
        "text": "the goal of these questions is to test the candidate\u2019s fundamentals and their ability to explain the concepts with ease."
    },
    {
        "text": "let us walk through a couple example questions that you may encounter in an interview and sample answers for them."
    },
    {
        "text": "practice questions 8. interviewer: can you explain p-value?"
    },
    {
        "text": "background: before we dive into the answer, let\u2019s go over the basics of hypothesis testing."
    },
    {
        "text": "hypothesis testing is used to test the validity of a claim via a null and an alternative hypothesis."
    },
    {
        "text": "this testing is done on a sample rather than on the entire population."
    },
    {
        "text": "let\u2019s walk through an example so you can easily follow along."
    },
    {
        "text": "let\u2019s say you have a friend that claims that the average gmat score for the students at his university is 650. now, you want to test his claim but don\u2019t have access to the data of all students."
    },
    {
        "text": "however, you are friends with quite a few people on facebook and can send them a survey link to fill out their score so you can see what the average is like for that sample."
    },
    {
        "text": "in this example, your hypotheses can be stated as follows: null hypothesis: the average gmat score at your friend\u2019s university is 650 or less."
    },
    {
        "text": "alternative hypothesis: the average gmat score at your friend\u2019s university is greater than 650. the idea here is that we test which hypothesis is better supported by the sample data you obtain via the survey."
    },
    {
        "text": "let us now look at how our hypothetical candidate answers this question."
    },
    {
        "text": "candidate: p-value is used to determine the statistical significance of hypothesis testing."
    },
    {
        "text": "largely, p-value is the probability of obtaining the observed results of a test, assuming the null hypothesis is correct."
    },
    {
        "text": "interviewer: hmm, that makes sense."
    },
    {
        "text": "can you explain how the significance of p-values is used for testing the null hypothesis?"
    },
    {
        "text": "candidate: when using p-value to test the null hypothesis, you... can reject null hypothesis and say that we have evidence for the alternative hypothesis when the p-value is significant."
    },
    {
        "text": "cannot reject null hypothesis but can state that we do not have evidence for the alternative hypothesis when the p-value is not significant."
    },
    {
        "text": "interviewer: okay, that sounds great so far."
    },
    {
        "text": "can you walk me through an example of where you used p-value to determine significance?"
    },
    {
        "text": "candidate: i conducted a small experiment to test a claim my friend made about the average gmat score at his university being 650. i designed the hypothesis as follows: null hypothesis: the average gmat score at my friend\u2019s university is 650 or less."
    },
    {
        "text": "alternative hypothesis: the average gmat score at my friend\u2019s university is greater than 650. after this, i collected data via a survey i sent to a subset of students at his university."
    },
    {
        "text": "i calculated the p-value based on the sample data and found that the average gmat score was 700 with a p-value of 0.02. with a significance level of 0.05, i found the p-value to be significant."
    },
    {
        "text": "this meant i could reject the null hypothesis and say i had evidence for the alternative hypothesis."
    },
    {
        "text": "p-values don\u2019t exactly prove something."
    },
    {
        "text": "in my experiment, it does not prove that my friend is incorrect but rather enables me to challenge his belief given that my p-value was significant."
    },
    {
        "text": "pro tip: notice how the interviewer went into some of the details to check if the candidate thoroughly understood the concept or if their knowledge of the subject was superficial."
    },
    {
        "text": "often, the best way to demonstrate expertise is to explain the concept using an example, preferably from a project you have worked on in the past."
    },
    {
        "text": "this highlights your practical knowledge of the subject and confirms your solid understanding of the fundamentals."
    },
    {
        "text": "9. interviewer: can you explain confidence interval to a nontechnical audience?"
    },
    {
        "text": "candidate: hmm, let me take a stab at it."
    },
    {
        "text": "we use confidence intervals when we do not know what the true values are but want to know the range within which the true value can fall with a degree of certainty."
    },
    {
        "text": "let me explain this with an example."
    },
    {
        "text": "let\u2019s say we want"
    },
    {
        "text": "to know the average height of toddlers in the us."
    },
    {
        "text": "the exhaustive way of calculating this would be to measure each toddler\u2019s height and then take an average."
    },
    {
        "text": "however, this may not be a feasible approach, so we draw out a random sample of toddlers and measure their height and take an average of that."
    },
    {
        "text": "now, to get a sense of the average height of all toddlers in the us, we calculate the confidence interval of the sample."
    },
    {
        "text": "for example, we can say that, based on a 95 percent confidence interval, the true average height of all toddlers is likely to be between thirty-three and thirty-eight inches."
    },
    {
        "text": "interviewer: thank you for that explanation."
    },
    {
        "text": "now statistically speaking, what are the key elements you need to calculate the confidence interval?"
    },
    {
        "text": "you don\u2019t have to state the formula\u2014just help me understand the different elements needed."
    },
    {
        "text": "candidate: okay, so for calculating the confidence interval, you would need to know the number of observations in the sample, the mean, and the standard deviation of the sample."
    },
    {
        "text": "depending on the confidence interval, for example 95 percent or 99 percent or any other, you would need the corresponding z-score."
    },
    {
        "text": "using these elements, you can calculate the confidence interval."
    },
    {
        "text": "pro tip: typically, you won\u2019t be asked to state the formula for any statistic, but understanding the key elements behind it is helpful."
    },
    {
        "text": "also, notice how the interviewer checks for a technical and nontechnical explanation in the same question."
    },
    {
        "text": "a data scientist is often required to communicate with both sets of audiences and fluency in explaining the concepts in both manners can be crucial for roles requiring both."
    },
    {
        "text": "extra questions for practice: what is the difference between one-tailed and two-tailed tests?"
    },
    {
        "text": "what is the difference between type i and type ii errors?"
    },
    {
        "text": "what is a normal distribution and how are z-scores calculated?"
    },
    {
        "text": "what is the central limit theorem?"
    },
    {
        "text": "why is it important?"
    },
    {
        "text": "what potential biases can you inflict when sampling?"
    },
    {
        "text": "experimental design"
    },
    {
        "text": "in industries where design and modification of products and processes are routine (e.g., research and development, product development), an approach called design of experiments (doe) is used to manage product and process improvements."
    },
    {
        "text": "doe is a stepwise method based on statistics that efficiently guides the identification and selection of changes that collectively will optimize performance."
    },
    {
        "text": "typically, this involves iterative testing of different factors, settings, and configurations, using the results of successive tests to further refine the product or process.20 when properly done, a doe approach produces more precise results while using many fewer experimental runs than other methods (e.g., one factor at a time or trial and error)."
    },
    {
        "text": "the outcome is a robust design that better meets customer specifications and production and delivery constraints.21 experimental design has different applications depending upon the industry."
    },
    {
        "text": "within product companies, it is popularly known as a/b testing and is carried out to test potential improvements to a website or a mobile application."
    },
    {
        "text": "within the health care or insurance industries, you may see applications involving experiments carried out to test process improvement ideas, such a decreasing patient/customer dissatisfaction."
    },
    {
        "text": "if the job role that you are applying to has experimental design or a/b testing as a required/preferred component, practice a few questions that you may anticipate in this area."
    },
    {
        "text": "even if you don\u2019t have direct experience in the area, being familiar with the basics and the process will be beneficial and will allow you to have a conversation with the interviewer on this subject."
    },
    {
        "text": "let\u2019s walk through a broad question on this topic so we can familiarize ourselves with the overall process and also along the way dive into a few technical aspects."
    },
    {
        "text": "practice question 10. interviewer: have you used experimental design on any of your projects?"
    },
    {
        "text": "candidate: yes, i worked on a clinical intervention project as part of the practicum during my masters."
    },
    {
        "text": "our practicum project was with healthfirst insurance company, and they wanted us to design and analyze an experiment as part of it."
    },
    {
        "text": "interviewer: okay, great."
    },
    {
        "text": "can you walk me through the details of this project?"
    },
    {
        "text": "specifically, how you designed the experiment and then analyzed the results coming of it?"
    },
    {
        "text": "candidate: sure."
    },
    {
        "text": "to begin with, the business goal of the broader project was to reduce the claims cost for diabetes patients."
    },
    {
        "text": "healthfirst wanted to launch a program for its members with diagnosed diabetes condition."
    },
    {
        "text": "this program would monitor the members\u2019 health on a periodic basis and encourage a suitable and healthy lifestyle to them to avoid any health-related complications arising out of having diabetes."
    },
    {
        "text": "with regular monitoring and maintaining a healthy lifestyle, healthfirst was hoping to reduce the number of claims from diabetes patients, thereby reducing the cost to the company."
    },
    {
        "text": "before the program was launched for all patients, it wanted to test whether launching such a program would be effective in reducing claims."
    },
    {
        "text": "this is where our team that designed and analyzed the experiment came in."
    },
    {
        "text": "we took a sample of one thousand patients with diabetes and split them into a test and control group."
    },
    {
        "text": "the test and control groups were selected based on similarity on certain parameters such as demographics, history of hospitalization and er visits, and type of medicines prescribed."
    },
    {
        "text": "once our test and control groups were identified, healthfirst launched the program on the test group, and we monitored key metrics affecting the result of the test over the next six months."
    },
    {
        "text": "the metrics we analyzed at the end of the six-month experiment were primarily around the number and number of claims of the test and control groups."
    },
    {
        "text": "pertaining to this, we also looked at what the claims were for, e.g., visit to primary care provider versus specialist, regular visit versus er visit, or in-network versus out-of-network provider used."
    },
    {
        "text": "based on our analysis, we found a significant drop in number of claims for the test group versus the control group proving the program to be effective."
    },
    {
        "text": "interviewer: that\u2019s great."
    },
    {
        "text": "thank you for walking me through the details."
    },
    {
        "text": "can you tell me how you made sure the test and control groups you chose were comparable?"
    },
    {
        "text": "candidate: sure, we took last twelve months of data as observation period."
    },
    {
        "text": "from this observation period, we drew out samples for test and control and compared them against the parameters i mentioned earlier: key demographic elements, number of visits, regular versus er visits, rate of hospitalization, etc."
    },
    {
        "text": "we ran a t-test to compare the means of the two samples across these different parameters."
    },
    {
        "text": "interviewer: got it."
    },
    {
        "text": "was there a different test that you used for the categorical data that you had?"
    },
    {
        "text": "let\u2019s say you looked at gender as part of the demographics parameters you used."
    },
    {
        "text": "candidate: yes, absolutely."
    },
    {
        "text": "for the categorical variables, i used the chi- squared test to check if the samples were similar."
    },
    {
        "text": "interviewer: that sounds good."
    },
    {
        "text": "was there a reason you used the t-test and not the z-test for the numerical variables to compare the means?"
    },
    {
        "text": "candidate: yes, the z-test is used when the population parameters, such as mean and standard deviation, are known whereas the t-test is used when the population parameters are unknown."
    },
    {
        "text": "given we drew out a sample from the total population of diabetes patients, i used the t-test."
    },
    {
        "text": "comments: experimental design is crucial because a cost is often associated with implementing something."
    },
    {
        "text": "in the example the candidate gave above, a cost is associated with the launch of the program."
    },
    {
        "text": "with the use of the testing that healthfirst did, it was able to evaluate whether there is merit in launching the program at scale."
    },
    {
        "text": "connecting the dots to the value your project brings in will help you differentiate yourself from your peers in the interview."
    },
    {
        "text": "extra questions for practice: how will you decide on the sample size to use for conducting the a/b test?"
    },
    {
        "text": "how long should the experiment run?"
    },
    {
        "text": "how often will you run an experiment?"
    },
    {
        "text": "what should your test versus control split be?"
    },
    {
        "text": "in interview rounds such as this one, the primary aspect the interviewer is testing you on is your fundamentals."
    },
    {
        "text": "make sure to revise the foundational"
    },
    {
        "text": "concepts used in data science, and you will breeze through this round!"
    },
    {
        "text": "13 \u201cprobability of compound events: definition & examples,\u201d study.com, accessed june 5, 2020."
    },
    {
        "text": "14 \u201ccompound probability\u201d, investopedia.com, accessed june 5, 2020."
    },
    {
        "text": "15 probability | theory, solved examples and practice questions,\u201d mba crystal ball, accessed may 17, 2020."
    },
    {
        "text": "16 probability | theory, solved examples and practice questions,\u201d mba crystal ball, accessed may 17, 2020."
    },
    {
        "text": "17 \u201cconditional probability\u201d, math goodies, accessed may 17, 2020."
    },
    {
        "text": "18 \u201cconditional probability: definition & examples\u201d, statistics how to, accessed may 17, 2020."
    },
    {
        "text": "19 jeremy orloff and jonathan bloom, \u201cconditional probability, independence and bayes\u2019 theorem,\u201d 18.05 introduction to probability and statistics (spring 2014)."
    },
    {
        "text": "massachusetts institute of technology: mit opencourseware."
    },
    {
        "text": "20 patton mcginley, \u201ctests of change: simulated design of experiments in healthcare delivery,\u201d patient safety & quality healthcare, july 14, 2009."
    },
    {
        "text": "21 ibid."
    },
    {
        "text": "programming questions programming in sql as any data science work starts with extracting and wrangling data, structured query language (sql) has become a must-have skill set for a data scientist."
    },
    {
        "text": "you will also notice that sql by far is one of the most requested skills in a data science job description."
    },
    {
        "text": "so, if your interview process has a programming component to it, your sql skills will very likely be tested."
    },
    {
        "text": "first, let me briefly recap relational databases."
    },
    {
        "text": "relational database management systems (rdbms) is the basis for sql and uses a structured format to store its data."
    },
    {
        "text": "the data in a relational database is organized in the form of tables and stored in a rows/columns format."
    },
    {
        "text": "typically, in an rdbms, you will find multiple tables that are related to each other."
    },
    {
        "text": "if you would like to brush up on your knowledge of rdbms a bit more or if this is relatively new to you, check out the references at the end of this book."
    },
    {
        "text": "you can use sql in many different database systems, such as mysql, microsoft sql server, ms access, oracle, sybase, informix, and postgres."
    },
    {
        "text": "these database systems will have minor differences in syntax from each other, but having knowledge of at least one will suffice for your interview."
    },
    {
        "text": "for this chapter, we will be using the sql syntax for microsoft sql server."
    },
    {
        "text": "the easiest and often best way to practice sql for interviews is by writing and executing queries in a sql environment so that you are confident with the syntax and can view the results being generated from your queries."
    },
    {
        "text": "if you would like to follow along in a sql environment, you can download the microsoft sql server trial version here: https://www.microsoft.com/en- us/sql-server/sql-server-downloads."
    },
    {
        "text": "to go through key sql concepts and to practice questions asked in a sql interview, let us start by creating the following three tables in sql server: customers create table customers( customerid int, firstname varchar(100), lastname varchar (100), email varchar(100), city varchar(100), state varchar(100) ); insert into customers (customerid , firstname, lastname, email, city, state) values (1, 'john', 'collins', 'john@example.com', 'chicago', 'il'), (2, 'jennifer','mccarthy','jennifer@example.com', 'new york', 'ny'), (3, 'anna','doe','anna@example.com', 'stamford', 'ct'), (4, 'maria', 'clark', 'maria@example.com', 'hartford', 'ct'), (5, 'william', 'yang', 'william@example.com', 'white plains', 'ny'); orders create table orders( orderid int, orderqty int, customerid int, productid int, createdat datetime ); insert into orders(orderid , orderqty , customerid , productid, createdat) values (1, 6, 2, 1, '20190618 10:34:00 am'), (2, 5, 1, 3, '20190721 11:21:00 am'), (3, 6, 3, 4, '20191115 09:12:00 pm'), (4, 2, 4, 5, '20190911 12:04:00 am'), (5, 3, 3, 2, '20190325 01:06:00 pm'), (6, 4, 5, 2, '20190204 05:22:00 am'); products create table products( productid int, productname varchar(100), price numeric ); insert into products(productid, productname, price) values (1, 'shampoo', 11.99), (2, 'conditioner', 15.99), (3, 'face wash', 5.99), (4, 'moisturizer', 8.99), (5, 'tooth paste', 2.99);"
    },
    {
        "text": "the basics for sql are pretty straightforward, but given how often you may use some of these operations in your job, interviewers tend to test you on the basics first."
    },
    {
        "text": "let\u2019s go through a few practice questions based on the tables we defined above so you have the sql fundamentals down!"
    },
    {
        "text": "here are some basic sql concepts we will be looking at in the following section: filter sort aggregate joins practice questions\u2014sql practice question #1: write a query to show customers who live in the state of ny and order them by their last name in ascending order."
    },
    {
        "text": "solution: select * from customers where state = 'ny' order by lastname; result set: practice question #2: write a query to show the total number of orders placed by each customer and sort by highest orders."
    },
    {
        "text": "showing totalorders by customerid will suffice."
    },
    {
        "text": "hint: you will need to use joins and aggregate operations for this query."
    },
    {
        "text": "solution: select customerid, count(orderid) as totalorders from orders group by customerid order by totalorders desc; result set: pro tip: the aggregate functions popularly used are sum, min, max, count, and avg."
    },
    {
        "text": "practice question #3: write a query to show states that have more than one customer record."
    },
    {
        "text": "hint: the where keyword cannot be used with aggregate functions, hence having is used."
    },
    {
        "text": "solution: select state, count(customerid) as totalcustomers from customers group by state having count(customerid) > 1; result set: with the basics covered, let\u2019s now dive into the following intermediate sql concepts: union, intersect sub-queries case statements"
    },
    {
        "text": "for the next question, suppose you have another table in addition to the three above: suppliers create table suppliers( supplierid int, name varchar(100), email varchar(100), city varchar(100), state varchar(100) ); insert into suppliers(supplierid, name, email, city, state) values (1, 'abc group', 'abc@example.com', 'chicago', 'il'), (2, 'xyz group','xyz@example.com', 'new york', 'ny'); practice question #4: write a query to show the list of cities where the customers and suppliers are from."
    },
    {
        "text": "solution: select city from customers union select city from suppliers; hint: you do not have specify distinct, as union will display each city only once."
    },
    {
        "text": "result set: practice question #5: write a query to show orderids that have orderqty greater than the average across all orders."
    },
    {
        "text": "solution:"
    },
    {
        "text": "select orderid from orders where orderqty > (select avg(orderqty) from orders); result set: practice question #6: write a query to show the first order of each customer."
    },
    {
        "text": "showing customerid, orderid will suffice."
    },
    {
        "text": "solution: select o.customerid, o.orderid, o.createdat from orders as o inner join ( select customerid, min(createdat) as mincreatedat from orders group by customerid ) as r on o.customerid= r.customerid and o.createdat= r.mincreatedat order by o.createdat result set: practice question #7: write a sql query to display the full name of a state."
    },
    {
        "text": "for example, if the state is il, show illinois."
    },
    {
        "text": "for this question, show the full names for the three states present in the customers table."
    },
    {
        "text": "solution:"
    },
    {
        "text": "select distinct state, case when state = 'il' then 'illinois' when state = 'ny' then 'new york' when state = 'ct' then 'connecticut' else 'state mapping is not available' end as state_fullname from customers; result set: while the majority of problems can be solved with filters, joins, and aggregates, you may encounter situations where using cte or window functions may be beneficial."
    },
    {
        "text": "for example, window functions are great when you need to aggregate without losing the individual line item information."
    },
    {
        "text": "window functions do not output aggregates as a single row for the group but rather as a column to the original line items that you have in the table."
    },
    {
        "text": "ctes are great to make your queries computationally less expensive."
    },
    {
        "text": "for example, with a query involving a where and join clause, sql will process the join first and then the where clause."
    },
    {
        "text": "in cases where the table size is quite large, join on all rows will be an expensive computation, especially if you are planning to remove those rows anyway with the where clause."
    },
    {
        "text": "in such cases, using a cte is computationally more effective where you can apply the where clause first and then do the join in the following statement."
    },
    {
        "text": "let\u2019s look at a couple of advanced practice questions so we are familiar with how to use ctes and window functions."
    },
    {
        "text": "we will review the following concepts: common table expressions (ctes) window functions"
    },
    {
        "text": "practice question #8: write a query to show the total revenue generated by each city."
    },
    {
        "text": "include state as a column in the final result set."
    },
    {
        "text": "revenue for each product can be calculated as a multiplication of price and order amount for that respective product."
    },
    {
        "text": "solution: \u2014first, find the amount for each order with amt (orderid, customerid, orderqty, price, amount) as ( select o.orderid, o.customerid, o.orderqty, p.price, (p.price * o.orderqty) as amount from orders as o left join products as p on o.productid = p.productid), \u2014next, find the total amount for each customer: totalamt (customerid, totalamount) as ( select customerid, sum(amount) as totalamount from amt group by customerid) \u2014finally, find the total revenue by city, state: select c.city, c.state, sum(t.totalamount) as revenue from customers as c join totalamt as t on c.customerid = t.customerid group by city, state; result set: practice question #9: write a query to show what percentage of a state\u2019s total revenue comes from each city in that state."
    },
    {
        "text": "assume for this you have the result set named rs with columns city, state, revenue (similar to the result set obtained as part of q8)."
    },
    {
        "text": "solution: with statetotal as ( select city, state, revenue, sum(revenue) over (partition by state) as staterevenue from rs) select city, state, revenue/staterevenue as percent_of_staterevenue from statetotal ; result set: here are some additional questions for practice: write a query to show total number of orders placed by a customer."
    },
    {
        "text": "if no orders have been placed by a customer, display 0."
    },
    {
        "text": "(hint: use left join.)"
    },
    {
        "text": "write a query to show customers that are from the same city."
    },
    {
        "text": "(hint: use self- join.)"
    },
    {
        "text": "write a query to show the list of cities that the customers are from."
    },
    {
        "text": "(hint distinct keyword.)"
    },
    {
        "text": "programming in python, r today\u2019s data science recruiting process almost always has a technical screening round."
    },
    {
        "text": "the company interviewing you is likely to test how adept your programming skills are."
    },
    {
        "text": "these assessments are more streamlined these days by way of an online test on a platform such as codesignal, hackerrank, or testdome."
    },
    {
        "text": "some companies may even test you outside of these online platforms by giving you an at-home exam or by conducting an in-person whiteboarding interview."
    },
    {
        "text": "irrespective of the modes of the tests, they are primarily geared toward testing whether a candidate is familiar with the coding fundamentals to extract, analyze data, and suggest conclusions."
    },
    {
        "text": "currently, python and r are the two most popular languages."
    },
    {
        "text": "your employer will often let you choose between them, but if they are an exclusive python or r shop, you will have to test on the language of their choice."
    },
    {
        "text": "in the following section, we will look at a few practice questions so the most frequently tested concepts are at the front of your mind before an interview."
    },
    {
        "text": "if either language is completely new to you, at the end of the book you will see a few resources that are good places to start."
    },
    {
        "text": "while you can use vanilla python or r to work with data, using libraries makes this process faster and more efficient."
    },
    {
        "text": "both languages have many useful libraries, but i\u2019m listing a few below that are popularly used."
    },
    {
        "text": "please note that these aren\u2019t ranked, as they are all useful in their own way."
    },
    {
        "text": "packages in python: numpy\u2014used for basic and advanced array operations pandas\u2014used for working with data frames scikit-learn\u2014used for common machine learning algorithms py-torch, tensorflow\u2014used for deep learning matplot-lib\u2014used for data visualization packages in r: dpylr\u2014used for data manipulation data.table tidyverse ggplot2\u2014used for data visualization caret\u2014used for classification and regression problems stringr\u2014used for string operations the data science programming universe covers a wide range of items."
    },
    {
        "text": "i have broken them down into three logical sections so you can focus your preparation in a sequential approach, covering the most tested areas."
    },
    {
        "text": "let\u2019s look at these three sections:"
    },
    {
        "text": "1. programming basics: this section covers basic programming constructs like use of different data types, arithmetic/logical/string operations, functions, looping constructs, and decision constructs."
    },
    {
        "text": "2. data wrangling: this part covers the essential skills required during pre- processing of data such as filter, subset, aggregate, and merge datasets."
    },
    {
        "text": "these functionalities are crucial for any data analysis work."
    },
    {
        "text": "3. data science/machine learning functionality: this section is specific to the use of libraries relevant to data science/machine learning."
    },
    {
        "text": "this includes, but is not limited to, building of classification and regression models, data mining solutions, and deep learning techniques."
    },
    {
        "text": "now that we have a handle on the key areas we need to focus on, let us dive into a few practice questions so we can flex our muscles for any programming questions that come up during an interview."
    },
    {
        "text": "practice questions\u2014python and r practice question #10: given a list of strings containing the name of the subject and its associated test score, find the subject with the highest test score."
    },
    {
        "text": "you can assume that this data is only for a single student."
    },
    {
        "text": "the string is in the format of \u201cstats,099\u201d where the first four characters represent the subject and the last three characters represent the test score."
    },
    {
        "text": "the test score is always between 0 and 100 and will be padded with leading zeroes if required."
    },
    {
        "text": "for example, if the score is 85, it will be displayed as \u2018085\u2019 in the string."
    },
    {
        "text": "write a function to display the subject with the highest test score."
    },
    {
        "text": "python input data: data = ['math,067', 'stat,085', 'econ,054', 'hist,092'] r input data: data = list('math,067', 'stat,085', 'econ,054', 'hist,092') python solution: def getmaxscore(data): max_score = 0 max_subject = '' for data_point in data: subject, score = data_point.split(',') if int(score) > max_score: max_score = int(score) max_subject = subject return max_subject"
    },
    {
        "text": "data = ['math,067', 'stat,085', 'econ,054', 'hist,092'] result = getmaxscore(data) print(\"subject with the highest test score is: \" +result) r solution: getmaxscore = function (data) { max_score = \"000\" max_subject = \"\" for (i in data) { x = strsplit(i, \",\")[[1]] if (x[2] > max_score) { max_score = x[2] max_subject = x[1] } } return(max_subject) } data = list('math,067', 'stat,085', 'econ,054', 'hist,092') result = getmaxscore(data)print(paste0 (\"subject with the highest test score is: \",result)) practice question #11: to practice our data wrangling skills, let\u2019s focus on writing code to the same result set as we did in the last sql question."
    },
    {
        "text": "write code to show what percentage of a state\u2019s total revenue comes from each city in that state."
    },
    {
        "text": "for this question, use the three tables as a starting point (customers, orders, products)."
    },
    {
        "text": "here are the tables again: customers"
    },
    {
        "text": "orders products python solution: for this solution, i read in the three data files using a csv in python and then proceeded with the required calculation."
    },
    {
        "text": "import pandas as pd #### read in data files customers = pd.read_csv(\"customers.csv\") orders = pd.read_csv(\"orders.csv\") products = pd.read_csv(\"products.csv\") ##### merge orders with product to get price column ord_prod = pd.merge(orders, products, on='productid', how='left') #### calculate $ amount per order ord_prod['amount'] = ord_prod['orderqty'] * ord_prod['price'] #### merge in customers table to get city, state columns ord_prod = pd.merge(ord_prod, customers, on='customerid', how='left') #### aggregate to get revenue by city and state rev_by_city = ord_prod.groupby(['city', 'state']).agg({'amount' : ['sum']}) rev_by_city.columns = ['rev_city'] rev_by_state = ord_prod.groupby(['state']).agg({'amount' : ['sum']}) rev_by_state.columns = ['rev_state'] rev_by_city = pd.merge(rev_by_city, rev_by_state, on = 'state', how='left') #### calculate percent revenue by city rev_by_city['perc_rev'] = rev_by_city['rev_city'] / rev_by_city['rev_state']"
    },
    {
        "text": "print(rev_by_city) r solution: similar to the python solution, i read in the csv files in r before proceeding with the required calculation."
    },
    {
        "text": "#### load libraries needed library(data.table) #### read in data files customers = read.csv(\"customers.csv\") orders = read.csv(\"orders.csv\") products = read.csv(\"products.csv\") ##### merge orders with product to get price column ord_prod = merge(x=orders, y=products[,c('productid', 'price')], by=c('productid'), all.x = t) #### convert to data.table ord_prod = as.data.table(ord_prod) #### calculate $ amount per order ord_prod[, amount:= orderqty*price] #### merge in customers table to get city, state columns ord_prod = merge(x=ord_prod, y=customers[,c('customerid', 'city', 'state')], by=c('customerid'), all.x = t) #### aggregate to get revenue by city and state rev_by_city = ord_prod[,."
    },
    {
        "text": "(rev_city=sum(amount)), by=c('city', 'state')] rev_by_state = ord_prod[,."
    },
    {
        "text": "(rev_state=sum(amount)), by=c('state')] rev_by_city = merge(x=rev_by_city, y=rev_by_state, by=c('state'), all.x = t) #### calculate percent revenue by city rev_by_city[, perc_rev:= rev_city/rev_state] rev_by_city"
    },
    {
        "text": "practice question #12: for this question, you are given an input data set with the following columns: sales volume, price."
    },
    {
        "text": "the end goal is to develop a linear regression model to predict sales volume based on the price of the product."
    },
    {
        "text": "to measure model performance, you will calculate the mean average percentage error (mape) for the test data."
    },
    {
        "text": "here are the specific functions you need to develop to get to the end result: 1. write a function to impute missing price values by average."
    },
    {
        "text": "2. write a function to calculate correlation of the dependent and independent variable."
    },
    {
        "text": "3. write a function to train and score the model on train and test set, respectively."
    },
    {
        "text": "for this, you can split the given input data set into train and test set by using an 80:20 split."
    },
    {
        "text": "4. write a function to calculate and display the mape for the test data."
    },
    {
        "text": "for this, you can assume that sales_volume will never be 0. python solution: def impute_data(data): data.fillna(data.mean(), inplace=true) return data def calc_corr(data): correlation = data['sales_volume'].corr(data['price']) return round(correlation,2) def run_linear_reg(x_train, y_train): linear_mod = linearregression() linear_mod.fit(x_train, y_train) return linear_mod def score_linear_reg(linear_mod, x_test, y_test): y_pred = linear_mod.predict(x_test) predictions = pd.dataframe({'actuals': y_test, 'predicted': y_pred}) return predictions def calc_mape(predictions): mape = metrics.mean_absolute_error(predictions['actuals'], predictions['predicted']) return round(mape,2) # load libraries import numpy as np import pandas as pd"
    },
    {
        "text": "from numpy import cov from sklearn.model_selection import train_test_split from sklearn.linear_model import linearregression from sklearn import metrics #### read in data filesdata = pd.read_csv(\"salesdata.csv\") #### impute missing price values data = impute_data(data) #### calculate correlation between the dependent and independent variable correlation = calc_corr(data) print(\"correlation between the dependent and independent variable is: \", correlation) #### split into train test x_train, x_test, y_train, y_test = train_test_split(data[['price']], data['sales_volume'], test_size=0.2, random_state=1) #### develop linear regression model on train data linearmod = run_linear_reg(x_train, y_train) #### score linear regression model on test data predictions = score_linear_reg(linearmod, x_test, y_test) print(predictions) #### calculate mape for the test periodmape = calc_mape(predictions) print(\"mape for the linear regression model is: \", mape, \"percent\") r solution: imputedata = function (data) { data$price[is.na(data$price)] = mean(data$price, na.rm=true) return(data) } calccorr = function (data) { corr = cor(data$sales_volume, data$price) return(round(corr,digits=2)) } runlinearreg = function (data) { linearmod = lm(sales_volume ~ price, data=data) return(linearmod) } scorelinearreg = function (linearmod, data) { pred = predict(linearmod, data) predictions = as.data.frame(cbind(pred, data$sales_volume))"
    },
    {
        "text": "names(predictions) = c('predicted', 'actuals') return(predictions) } calcmape = function (predictions) { mape = mean(abs(predictions$actuals- predictions$predicted)/(predictions$actuals)) return(round((mape100),digits=2)) } #### read in data files data = read.csv(\"salesdata.csv\") #### impute missing price values data = imputedata(data) #### calculate correlation between the dependent and independent variable corr = calccorr(data) print(paste0(\"correlation between the dependent and independent variable is: \", corr)) #### split into train test samplesize <- floor(0.80 nrow(data)) # set the seed to make your partition reproducible set.seed(123) train_ind <- sample(seq_len(nrow(data)), size = samplesize) traindata <- data[train_ind, ] testdata <- data[-train_ind, ] #### develop linear regression model on train data linearmod = runlinearreg(traindata) summary(linearmod) #### score linear regression model on test data predictions = scorelinearreg(linearmod, testdata) #### calculate mape for the test period mape = calcmape(predictions) print(paste0(\"mape for the linear regression model is: \", mape, \"percent\"))"
    },
    {
        "text": "comments: i have kept the code simple to make it easy to follow."
    },
    {
        "text": "however, this code can be generalized further if needed."
    },
    {
        "text": "for example, the correlation calculation function references the columns directly by their name (sales_volume, price)."
    },
    {
        "text": "instead of hard coding the column names in the functions, you can pass them by reference so the correlations can be calculated for any two columns."
    },
    {
        "text": "when answering these types of questions in the coding test, follow a simple approach first, and then you can work on generalizing and making the code more efficient if time permits."
    },
    {
        "text": "the primary goal should be to solve the problem at hand in a simple manner and pass all test cases."
    },
    {
        "text": "additionally, here a few resources you can use to practice your coding skills: leetcode hackerrank codesignal testdome coderbyte"
    },
    {
        "text": "case questions interviews involving case studies are quite common for many job roles."
    },
    {
        "text": "for data science roles, these have evolved to mimic the work the data scientist will be doing if hired."
    },
    {
        "text": "they\u2019re a great way for companies to simulate a data science project and assess how a candidate will perform in the real world."
    },
    {
        "text": "before we dive into any practice questions, let\u2019s understand what interviewers are looking for in a case interview and how to best tackle them."
    },
    {
        "text": "what is an interviewer testing you on in a case interview?"
    },
    {
        "text": "ability to synthesize information\u2014interviewers are looking to see if you can piece together information on multiple fronts and come up with coherent and concise ideas."
    },
    {
        "text": "most case interviews begin with a broader prompt giving an overarching view of the problem statement."
    },
    {
        "text": "the interviewer is looking at whether you can break down this top-level information and work toward a solution by putting together the jigsaw pieces along the way."
    },
    {
        "text": "analytical thinking\u2014given the nature of the job role for a data scientist, the interviewer will be judging you on your ability to think from an analytical lens and highlight how data can be best used to solve the business problem posed to you."
    },
    {
        "text": "skills\u2014interviewers are looking for how well you communicate your approach and the findings and how you summarize the overall problem."
    },
    {
        "text": "they will also be looking at your ability to communicate with both a technical and nontechnical audience."
    },
    {
        "text": "product sense\u2014if you\u2019re interviewing for a product company, they will be evaluating you on your \u201cproduct sense\u201d\u2014what makes a product great and what doesn\u2019t."
    },
    {
        "text": "you can practice developing your product sense by looking at"
    },
    {
        "text": "everyday things critically."
    },
    {
        "text": "you may ask yourself questions like: why is my iphone so easy to use?"
    },
    {
        "text": "what is so great about the instagram story feature?"
    },
    {
        "text": "what makes it easy to search for bed and breakfasts on airbnb?"
    },
    {
        "text": "if you would like to take it a bit further and wear the product manager hat for a while, then start to think about what can make this product better."
    },
    {
        "text": "while you may not be asked product enhancement questions in a data science interview, practicing along these lines will allow you to think outside the box and will push your creative mindset."
    },
    {
        "text": "what is a good approach to tackle case questions?"
    },
    {
        "text": "ask and understand the \u201cwhat\u201d\u2014when you are given the case prompt, take a minute or two to carefully understand the question and the objective behind it, and confirm your understanding of what is being asked."
    },
    {
        "text": "you may know the answer to the question off the bat, and that\u2019s okay."
    },
    {
        "text": "rather, that\u2019s how it should be."
    },
    {
        "text": "you will get to the finer aspects later on, but as the first step, understand what the problem statement is and what is it you are tasked to solve for."
    },
    {
        "text": "dive into the \u201cwhy & how\u201d\u2014once you have a handle on the goals, move into the \u201cwhy & how.\u201d for example, if it\u2019s a profitability case, identify the drivers of profitability and then move to understanding how changes in these drivers\u2019 impact profitability."
    },
    {
        "text": "write down your structure as you do this so the interviewer can give you early feedback if you are steering away from where they want you to go."
    },
    {
        "text": "hypothesize and brainstorm options\u2014based on the overall goal, build hypotheses and talk through the various options as you see fit for the case."
    },
    {
        "text": "this is also a great time in the interview to ask if additional data points are available to dig in further and to validate your assumptions with your interviewer along the way."
    },
    {
        "text": "actively communicate thought process\u2014having given multiple case interviews as part of the recruiting process after his mba, ganapati raghunathan offered the following insight: \u201cit is key to keep communicating your thought process with the interviewer."
    },
    {
        "text": "the interviewer will usually pull the candidate back on track if they go on a tangent.\u201d summarize and recommend\u2014once you have evaluated different options"
    },
    {
        "text": "and essentially walked the interviewer through your \u201cdecision tree,\u201d summarize your recommendation/conclusion, list out any key assumptions you have made while arriving at the conclusion, and state any risks that this recommendation may bring in."
    },
    {
        "text": "other things to watch out for: if in the process you ever stuck and things seem daunting, think of yourself as the interviewer\u2019s colleague."
    },
    {
        "text": "think of the question as if you were leading the project."
    },
    {
        "text": "this will put you right back in the driver\u2019s seat and will give you the confidence to ask the right questions and formulate an approach."
    },
    {
        "text": "if you find yourself rambling and giving long-winded answers, pause."
    },
    {
        "text": "take a step back and ask for a couple minutes to work through your thoughts."
    },
    {
        "text": "structure your response and write down key points and then start to answer again."
    },
    {
        "text": "remember, there is never a wrong time to ask for a couple minutes to structure your response."
    },
    {
        "text": "do not be fixated on only one area, especially if the interviewer is not keen on going in that direction."
    },
    {
        "text": "read the cues from your interviewer as they often will nudge you in the correct direction."
    },
    {
        "text": "do not get swayed into building a perfect data-driven solution only."
    },
    {
        "text": "validate it with your business intuition and assess whether it fulfills the broader business objective before making a recommendation."
    },
    {
        "text": "let us now look at a few practice cases."
    },
    {
        "text": "practice case #1\u2014churn prediction the first practice case that we will look at starts off as a generic case question and then gets into the specifics of how a data science approach can be used to solve the problem."
    },
    {
        "text": "case prompt: beautybox is an online monthly subscription service that sends its subscribers a box of seven selected samples of makeup and beauty-related products."
    },
    {
        "text": "the products include skincare items, perfumes, and other cosmetics."
    },
    {
        "text": "over the past year or so, they have noticed a decline in profits."
    },
    {
        "text": "what factors may be contributing to this and what can they do to alleviate the situation?"
    },
    {
        "text": "candidate: can i take a couple minutes to frame my thoughts?"
    },
    {
        "text": "interviewer: absolutely!"
    },
    {
        "text": "take your time."
    },
    {
        "text": "pro tip: taking a couple minutes at the start of the case interview to organize your thoughts is extremely beneficial."
    },
    {
        "text": "this will allow you time to consider the different factors involved in solving the business challenge."
    },
    {
        "text": "you can also take this time to understand the case question better and ask any clarifying questions to the interviewer."
    },
    {
        "text": "candidate: i had a few questions before i dive into the answer."
    },
    {
        "text": "can you help me understand the business model of beautybox?"
    },
    {
        "text": "do its customers subscribe for a given period of time and then renew after that?"
    },
    {
        "text": "and are they allowed to cancel at any time?"
    },
    {
        "text": "also, does it have a different product mix that its customers can choose from?"
    },
    {
        "text": "interviewer: great questions!"
    },
    {
        "text": "so, its customers can choose from a three-, six-, or twelve-month subscription option."
    },
    {
        "text": "and they are allowed to cancel at any time."
    },
    {
        "text": "currently, it only has one subscription box to offer to their customer base."
    },
    {
        "text": "each month it sends a beauty box containing seven different cosmetic items for its customers to try."
    },
    {
        "text": "candidate: makes sense."
    },
    {
        "text": "thank you for that information."
    },
    {
        "text": "as i am thinking through the question you initially asked me, i think there could be a few different factors that could affect their profits."
    },
    {
        "text": "here\u2019s a breakdown of the factors i\u2019m considering: revenue \u2013 number of subscriptions sold \u2013 price per subscription cost \u2013 cost of goods produced \u25a0product cost \u25a0fulfillment cost \u2013 cost per customer"
    },
    {
        "text": "\u25a0customer acquisition cost \u25b6discounts for first-timers, marketing cost, etc."
    },
    {
        "text": "\u25a0customer retention cost \u25b6customer support, renewal management, etc."
    },
    {
        "text": "interviewer: that makes sense."
    },
    {
        "text": "here\u2019s what we know about the volume of subscriptions and the total costs to the company in 2019. breakdown of revenue and cost for beautybox in 2019 candidate: hmm, given that a single product is available to the customers, i assume the price for all is the same."
    },
    {
        "text": "let me know if my assumption is incorrect."
    },
    {
        "text": "and i can see the costs have remained relatively steady over the year from the graph you shared with me."
    },
    {
        "text": "looking at this data, i suspect the number of subscriptions is driving the profit down."
    },
    {
        "text": "do we know anything more on how the subscription volume has changed over the months in 2019?"
    },
    {
        "text": "interviewer: your assumption about the price is correct."
    },
    {
        "text": "beautybox has seen a steady decline in the number of subscriptions over the last three quarters."
    },
    {
        "text": "it has seen an increasing number of cancellations."
    },
    {
        "text": "looking at this graph, can you tell me what is the average quarterly churn rate?"
    },
    {
        "text": "comment: notice how the candidate has stated their assumptions along the way."
    },
    {
        "text": "openly stating the assumptions you make is a good strategy so that, in"
    },
    {
        "text": "case they are not valid, the interviewer can jump in and course correct if needed."
    },
    {
        "text": "breakdown of total number of customers vs. total cancelled in 2019 candidate: hmm, looking at the graph, i can see that the average churn rate is 16 percent."
    },
    {
        "text": "i calculated the churn rate for each quarter as the number of subscribers cancelling divided by the total number of subscribers in that quarter."
    },
    {
        "text": "comments: in case you do not recall a particular formula in the interview, you could ask the interviewer."
    },
    {
        "text": "although, before you directly ask for the formula, state your understanding of what the calculation should be and confirm the understanding."
    },
    {
        "text": "this lets the interviewer know that even if you don\u2019t have the solution at your immediate disposal, you are able to think of an approach."
    },
    {
        "text": "interviewer: that\u2019s correct."
    },
    {
        "text": "the team at beautybox wants to know if it can identify the customers who are likely to churn before they actually cancel."
    },
    {
        "text": "what model can you build for this?"
    },
    {
        "text": "candidate: absolutely."
    },
    {
        "text": "we can identify the customers who are likely to cancel with the help of machine learning techniques."
    },
    {
        "text": "in fact, if the company\u2019s profits are declining due to an increasing number of customers canceling the subscription, implementing churn modeling techniques to retain the customers is definitely worth exploring."
    },
    {
        "text": "from what i understand, usually the cost to acquire a customer significantly outweighs the cost to retain a customer."
    },
    {
        "text": "so, if beautybox is able to identify the customers who are likely to leave, it can take any necessary action to try to retain them."
    },
    {
        "text": "comments: notice how the candidate not only mentions that it is possible to predict churn but also shares what beautybox can do once they are able to predict it."
    },
    {
        "text": "this shows that the candidate has technical understanding of the subject and is also able to explain the advantages of the method in business terms."
    },
    {
        "text": "candidate: coming to the modeling aspect for this, i believe you can use regression or tree-based models to predict the likelihood of customers who would cancel."
    },
    {
        "text": "in the case of regression, one of the ways to do it is to build a logistic regression model that predicts the probability of a customer churning."
    },
    {
        "text": "similarly, for tree-based models, random forest or boosted trees can be used to make the same prediction."
    },
    {
        "text": "while these are some of the techniques you can use to build the models, you can assess which technique gives you the best results with the help of cross validation and comparing out of sample accuracy across different models."
    },
    {
        "text": "interviewer: that sounds great."
    },
    {
        "text": "can you tell me what data you would use to build such a model?"
    },
    {
        "text": "candidate: multiple data points can affect the churn rate for beautybox."
    },
    {
        "text": "broadly speaking, they can look into the following categories: demographic information: demographic data of the customers such as age, gender, income level, and employment status can be used as an input into the model."
    },
    {
        "text": "interactions with support team: data such as number of times a customer has interacted with the support team, total number of complaints made, time taken to address each complaint, and time between complaints are great informers of how the customer interacts with the company\u2019s support team."
    },
    {
        "text": "customer satisfaction can be inferred from these data points to an extent."
    },
    {
        "text": "all in all, they are great inputs to estimate churn."
    },
    {
        "text": "customer account information: it is also useful to look at when the customer first subscribed, what brought them in (promotional offer, friend\u2019s referral, etc."
    },
    {
        "text": "), how long they have been a customer, subscription type they use, and if they have canceled and resumed the subscription at any point."
    },
    {
        "text": "social media information: if possible, layering in the social media data would be an excellent addition."
    },
    {
        "text": "this can be done from the perspective of what the customers are talking about the product on social media to get an idea of the customer sentiment."
    },
    {
        "text": "interviewer: excellent!"
    },
    {
        "text": "those are some good data points to include."
    },
    {
        "text": "now, can you tell me what metrics you will use to measure model accuracy?"
    },
    {
        "text": "pro tip: we have covered the details on these accuracy metrics in ."
    },
    {
        "text": "feel free to browse the exact definitions in there to recap!"
    },
    {
        "text": "candidate: to measure the accuracy of a churn prediction model, i\u2019ll start by developing the 2x2 confusion matrix with the predicted classes represented in the columns and the actual cases represented in the rows."
    },
    {
        "text": "the first metric to look at is the total accuracy of the model measured as number of cases correctly predicted/total number of cases."
    },
    {
        "text": "next, with the help of the confusion matrix, i will look at the false positives and the false negatives."
    },
    {
        "text": "false positive will falsely identify someone who was not going to churn as someone who churned, whereas false negative will measure the number of cases in which you failed to identify someone who was likely to churn."
    },
    {
        "text": "these two metrics are important because if false positives are too high, you end up investing in customers who would have stayed anyway."
    },
    {
        "text": "if false negatives are too high, then you miss out on identifying people who are going to churn and lose the opportunity to persuade them to stay."
    },
    {
        "text": "a cost is associated with both of these scenarios."
    },
    {
        "text": "hence, we need a balance between both metrics."
    },
    {
        "text": "the f-score metric can be looked at to identify the required balance."
    },
    {
        "text": "interviewer: that sounds great."
    },
    {
        "text": "what would you recommend the business to do once they have identified the customers as likely to churn?"
    },
    {
        "text": "candidate: once the business knows which customers are likely to cancel the subscription, they can take action to prevent this from happening."
    },
    {
        "text": "from the models built to predict churn, they will be able to isolate the key indicators of churn."
    },
    {
        "text": "those indicators will be the call to action."
    },
    {
        "text": "for example, an indicator can be multiple phone calls to the customer care team with the issue status still resolved."
    },
    {
        "text": "when these indicators are identified, beautybox can design a churn mitigation plan and take action before the customer decides to cancel."
    },
    {
        "text": "the mitigation plan can be formulated at a customer segment level to make it more targeted and to concentrate efforts toward its high-valued customers."
    },
    {
        "text": "the segmentation, for example, can group its customers into three categories: high-valued, medium-valued, and low-valued customers."
    },
    {
        "text": "in terms of priority, the high- and medium-valued customers should be action-ed first."
    },
    {
        "text": "comments: overall, the candidate did a good job in answering the case questions."
    },
    {
        "text": "they were able to talk about the data science techniques applicable to this problem and to give an overall recommendation as to how the insights from that can be leveraged for the business."
    },
    {
        "text": "they stated their assumptions along the way and confirmed their understanding before stating any conclusions."
    },
    {
        "text": "practice case #2\u2014a/b testing when interviewing for a product company, a case question determines whether a candidate can methodically tackle a broad question and make a recommendation for the team to act on."
    },
    {
        "text": "the nature of work for a data scientist can differ based on the organization structure of the data science team."
    },
    {
        "text": "data scientists can be embedded in the product team working alongside the product managers, engineers, ui/ux designers, etc."
    },
    {
        "text": "data scientists working within the product team bring in an analytical lens when working on problems."
    },
    {
        "text": "they are expected to explore and analyze data sets to uncover insights for the team."
    },
    {
        "text": "within the product realm, when a decision about whether or not to launch a feature comes up, the data scientist helps by"
    },
    {
        "text": "designing experiments and tracking metrics to measure experiment performance."
    },
    {
        "text": "typically, data scientists within a product team aren\u2019t tasked with data engineering activities."
    },
    {
        "text": "while there is an element of merging and aggregating data sets that is involved with any analytics work, building etl pipelines isn\u2019t part of a data scientist\u2019s role description."
    },
    {
        "text": "the same goes with deploying machine learning models to productions."
    },
    {
        "text": "data scientists build models and conduct the analysis as needed, but within a product team, the engineers are often the ones who deploy the models to production."
    },
    {
        "text": "data scientists can also be a part of a centralized/core function."
    },
    {
        "text": "data scientists as part of a central team consult and work on different projects across the organization."
    },
    {
        "text": "the core team can be made up of data scientists, machine learning engineers, and data engineers."
    },
    {
        "text": "the work of the core team can potentially be of research nature unlike the data scientist on the product team."
    },
    {
        "text": "let us now dive into our practice case #2. this question throws light on the type of cases you can expect when interviewing for a product company."
    },
    {
        "text": "interviewer: facebook is considering showing more ads in place of the \u201cpeople you may know\u201d feature."
    },
    {
        "text": "do you think the team should go ahead with this implementation?"
    },
    {
        "text": "candidate: i would like to start by talking about the overall goals for facebook and what i think the goals for the features you described are and then go from there."
    },
    {
        "text": "interviewer: sounds good."
    },
    {
        "text": "candidate: facebook enables people to stay connected with their family and friends, and its goal is to give people a platform to build a community with whom they can share their experiences."
    },
    {
        "text": "from what i know, the \u201cpeople you may know\u201d feature directly correlates with their goal and enables users to build their existing networks."
    },
    {
        "text": "furthermore, facebook\u2019s primary source of revenue is ad sales, some of which come from the ads directly displayed on the news feed, which is the feature we are talking about i assume."
    },
    {
        "text": "interviewer: yes, you are correct about the news feed assumption and the goals you mentioned are aligned correctly as well."
    },
    {
        "text": "candidate: great, now i would like to think through the pros and cons of each feature."
    },
    {
        "text": "pros and cons by feature while there are trade-offs for choosing either feature, we should align these decisions to any business objective that facebook has."
    },
    {
        "text": "is there a specific short- or long-term goal the team is working toward?"
    },
    {
        "text": "interviewer: no, not specifically for the scope of this question."
    },
    {
        "text": "candidate: okay."
    },
    {
        "text": "in that case, i propose running an a/b test to assess the impact of showing more ads to a randomized group of users and compare it against a control group who will see the news feed as is."
    },
    {
        "text": "interviewer: sounds good."
    },
    {
        "text": "what metrics will you track when you run the a/b test?"
    },
    {
        "text": "candidate: let\u2019s see."
    },
    {
        "text": "from the point of view of the two options, i will look at the following: ads (metrics related to monetization) \u2013 average revenue per user \u2013 average revenue per active user people who you may know (metrics related to engagement and retention) \u2013 likes"
    },
    {
        "text": "\u2013 comments \u2013 shares \u2013 clicks \u2013 total number of users \u2013 total number of active users interviewer: thank you for listing those out."
    },
    {
        "text": "i see that you have listed out average revenue per active user specifically."
    },
    {
        "text": "is there a reason you have in mind to track that?"
    },
    {
        "text": "candidate: yes, absolutely."
    },
    {
        "text": "from what i understand, facebook users can be grouped into two key segments: 1. active users 2. inactive users active users engage with the product often and are the first to react to any product changes."
    },
    {
        "text": "hence, we must track any changes in the product usage of the test group."
    },
    {
        "text": "interviewer: okay, let\u2019s say we got the results back from the a/b test run over a two-week period."
    },
    {
        "text": "based on these results, what is your recommendation?"
    },
    {
        "text": "a/b test results candidate: on one hand, while i see average revenue going up by 1 percent overall and 2 percent for active users, the number of likes and shares have gone down, indicating that the user engagement has taken a hit."
    },
    {
        "text": "while the comments metric has gone up, we must evaluate if these are positive or negative sentiments."
    },
    {
        "text": "people could be negatively commenting about the increase in ads, so looking at this increase in isolation may be deceptive."
    },
    {
        "text": "in summary, given that facebook\u2019s primary goal is to build a platform to connect users, i think a significant impact in the engagement metrics is a sign that something is not right."
    },
    {
        "text": "facebook needs to find that optimal point where engagement is not impacted but the revenue generated increases."
    },
    {
        "text": "for now, i would recommend to not show ads in place of the \u201cpeople you may know\u201d feature."
    },
    {
        "text": "comments: the candidate offered a very structured and thoughtful discussion around the pros and cons of using one feature more over the other."
    },
    {
        "text": "the candidate was able to use the data provided well and to convince the interviewer that they have a reasonable plan in place to approach such a problem."
    },
    {
        "text": "questions for practice relating to case #2: how do you measure the success of instagram stories?"
    },
    {
        "text": "how will you forecast user sign up for a new product?"
    },
    {
        "text": "an online platform suddenly saw an increase in sign-ups."
    },
    {
        "text": "what could be the reasons for this?"
    },
    {
        "text": "practice case #3\u2014business analytics let us look at another case that centers around the use of business analytics to solve the problem at hand."
    },
    {
        "text": "interviewer: a major hotel chain has been experiencing slow growth and declining profits in the last few years."
    },
    {
        "text": "the ceo has hired you to help them understand the drivers behind this and ultimately help increase profitability."
    },
    {
        "text": "the hotel chain has thirty-nine hotels spread across the united states and, despite major back-end cost savings, it is experiencing low profits."
    },
    {
        "text": "candidate: i have a few questions before i jump into the case."
    },
    {
        "text": "interviewer: sure, go ahead."
    },
    {
        "text": "candidate: i want to understand the hotel\u2019s business model better."
    },
    {
        "text": "is it centrally owned or does each location operate as its own franchisee and has an owner?"
    },
    {
        "text": "interviewer: the hotel chain is centrally owned by our client, and each location has a hotel manager and supporting staff to run the operations."
    },
    {
        "text": "candidate: okay, i would also like to understand the hotel profitability better."
    },
    {
        "text": "are all stores equally profitable or do we see variations?"
    },
    {
        "text": "interviewer: some are more profitable than the others, and we see variations throughout."
    },
    {
        "text": "but that being said, irrespective of the location, all hotels have seen a decline in profits over the last two years."
    },
    {
        "text": "candidate: thank you."
    },
    {
        "text": "you also mentioned in the beginning that the hotel chain has cut down on back-end costs."
    },
    {
        "text": "can you tell me how the cost savings were achieved?"
    },
    {
        "text": "interviewer: sure, the hotel chain cut down on the costs by optimizing labor scheduling and staff training."
    },
    {
        "text": "with this approach, the staff was not underutilized, and cross-trained employees could lend a hand in another role when needed."
    },
    {
        "text": "candidate: got it."
    },
    {
        "text": "additionally, i would like to understand if the number of bookings has changed over the past two years."
    },
    {
        "text": "interviewer: we have the following data from the ceo on how the costs and bookings have changed over 2018 and 2019. costs and bookings for 2018, 2019. candidate: the information provided here suggests the decrease in operating costs is correlated with the decline in number of bookings."
    },
    {
        "text": "we see a significant dip in the operating costs post-q4 in 2018, which is when we see"
    },
    {
        "text": "the decline in number of bookings start."
    },
    {
        "text": "if cost saving was primarily driven by cutting down on labor costs, this to me suggests a few things: it looks like in controlling costs the customer service got impacted."
    },
    {
        "text": "the rationale behind my thinking is that in optimizing labor scheduling and cross-training the staff, the level of service delivered wasn\u2019t at the same level."
    },
    {
        "text": "and if this is true, within the hospitality industry, bad service will lose customers."
    },
    {
        "text": "we see this especially in q4 in 2018, where seasonality otherwise would have suggested a peak in bookings, as that is when most folks travels due to holidays."
    },
    {
        "text": "but in this case, we see a gradual drop in number of bookings starting to show in q4 2018 itself."
    },
    {
        "text": "we can validate this by looking at competitor bookings and see how the client\u2019s numbers compare to them."
    },
    {
        "text": "if the hotel chain cut down on costs in other areas, it would have an impact in the number of bookings, such as: the hotel chain cut down on marketing/advertising, leading to lower bookings it reduced the number of promotions it runs the hotel chain could also get impacted by external factors, such as: decrease in competitor prices leading to customers switching to other hotel chains general decrease in bookings due to any external factors such as the recent covid-19 virus launch of a new hotel chain interviewer: so, we know that in general the competitors haven\u2019t had any major change in their pricing strategy and overall bookings in the industry have remained in the range as one would expect."
    },
    {
        "text": "your hypothesis on the cost control measures impacting customer"
    },
    {
        "text": "satisfaction is correct."
    },
    {
        "text": "the hotel chain has seen a decrease in customer satisfaction as the cost control measures were put in place."
    },
    {
        "text": "what would you suggest the hotel chain do in this case then?"
    },
    {
        "text": "candidate: we need to better understand what aspects of the service customers are dissatisfied with."
    },
    {
        "text": "once we have identified these factors, a strategy to improve the existing service while balancing the costs need to be put in place."
    },
    {
        "text": "interviewer: okay, can you tell me how the hotel chain can measure customer dissatisfaction?"
    },
    {
        "text": "candidate: sure, they can do this in a few ways: by looking at the complaints data at the hotel chain service desk by looking at the customer service logs to see the volume and type of complaints logged by doing sentiment analysis to see what the hotel guests are saying on social media essentially, the hotel chain can leverage different data avenues available to them to see how the key metrics relating to customer satisfaction have changed over the last two years."
    },
    {
        "text": "while doing so, my recommendation is to identify the root causes of customer satisfaction as well."
    },
    {
        "text": "with the insights into the drivers of low customer satisfaction, the hotel chain can develop a plan toward enhancing customer experience, thereby increasing its bookings and profits."
    },
    {
        "text": "interviewer: that sounds good."
    },
    {
        "text": "the ceo is keen on using data and analytics to enhance their customer satisfaction and experience."
    },
    {
        "text": "how do you recommend they do this?"
    },
    {
        "text": "candidate: i can think of a few for this."
    },
    {
        "text": "app for essentials: technology use for hotels is evolving a lot these days, and providing the guest with the latest in technology can be a game changer."
    },
    {
        "text": "for example, the hotel chain can have a mobile app that allows them to request"
    },
    {
        "text": "for services by the click of a button, allow them to check in online, and keep a track of their reward points."
    },
    {
        "text": "personalization: the hotel chain can look at how it can personalize each customer\u2019s experience while staying at its facility."
    },
    {
        "text": "for example, it can look at its different customer segments and understand what feature/service will be valued by each."
    },
    {
        "text": "for families coming in to stay at its hotels, it can give small gifts to the children to keep them entertained and ensure extra towels are in the room before the family checks in."
    },
    {
        "text": "small gestures such as this have shown to enhance customer experience, and such customers are likely to recommend the hotel to their friends."
    },
    {
        "text": "improved recommendations: the hotels can establish a connection with a guest as soon as they have made a booking."
    },
    {
        "text": "the communication can include details on what they can do during the stay and the facilities they can use at the hotel."
    },
    {
        "text": "these recommendations can be tailored to the personal tastes of the guest."
    },
    {
        "text": "for example, custom itineraries can be curated based on the guest\u2019s personal preferences and tastes."
    },
    {
        "text": "the hotel chain can look at a way of integrating their crm system with the social media data."
    },
    {
        "text": "with a view on the social media activity of its guests, it can easily unlock insights into the guests\u2019 habits and interests and provide tailored recommendations for their travel."
    },
    {
        "text": "ask and deliver: the hotel chain can get real-time feedback from its guests during the stay and improve their service during the same trip."
    },
    {
        "text": "this can be a shift from gaining retrospective feedback to having a continuous feedback loop with the guest and addressing their needs in real time."
    },
    {
        "text": "it can leverage the mobile app to get feedback from the guests during their stay and routinely check in to see if they have everything they need."
    },
    {
        "text": "provide exceptional service: the hotel chain needs to look at what the guest complaints so far have been and come up with a tactical plan to resolve them."
    },
    {
        "text": "if the service levels have dropped due to labor optimization, then the scheduling needs to be revised to ensure the staff isn\u2019t overworked."
    },
    {
        "text": "overworked staff could lead the service levels to be poor."
    },
    {
        "text": "the hotel chain needs to re-establish its service standards and train its employees and enable them to give its guests a fabulous experience when staying at the hotel."
    },
    {
        "text": "the hotel chain has ample opportunity to use data and analytics to improve its customer experience."
    },
    {
        "text": "from a tactical standpoint and immediate next steps,"
    },
    {
        "text": "my recommendation for the hotel chain is to address the primary reasons for customer dissatisfaction."
    },
    {
        "text": "and in parallel, it should look at further enhancing the customer experience and increase retention with the help of data analytics."
    },
    {
        "text": "comments: the candidate overall did a good job with the case and asked good clarifying questions at the outset."
    },
    {
        "text": "the candidate, however, could have done a better job at structuring their response when answering the question around the drivers of low profitability."
    },
    {
        "text": "the candidate thought through the reasons sequentially, but putting together a broader framework and then diving into the details one by one would have been a better approach in this case."
    },
    {
        "text": "they also immediately jumped to conclusions when data around cost and bookings was given."
    },
    {
        "text": "an ideal approach would involve thinking through the different drivers of low profitability (internal and external), stating the observations based on the data given, and then stating the findings connected to the large business problem."
    },
    {
        "text": "in conclusion, at some point in the interview process, you can expect to encounter a case-type question in some shape or form."
    },
    {
        "text": "to be well prepared for one, consider doing mock cases with a friend."
    },
    {
        "text": "the more cases you practice, the more comfortable you will be with the case interview process."
    },
    {
        "text": "and be sure to practice cases in the relevant focus areas of the company you\u2019re interviewing for."
    },
    {
        "text": "aniket deshpande, senior data scientist at aetna, shared this excellent advice with me: \u201cmost companies ask questions related to their domain."
    },
    {
        "text": "the cue here is to research some practice questions related to their domain before interviewing for any company.\u201d with that being said, i will leave you with a few tips to help you crack the case interview."
    },
    {
        "text": "pro tip: when given a case: take a step back and think of a) any clarifying questions you want to ask before you dive in and b) possible approaches to solve the problem."
    },
    {
        "text": "when presented with data, take the time to think through the observations and see how it translates back to the larger problem asked."
    },
    {
        "text": "always state any assumptions you are making."
    },
    {
        "text": "talk through any mathematical calculations so the interviewer can follow along with you and course correct if needed."
    },
    {
        "text": "when concluding the case, connect your recommendations with the larger problem and lead with that."
    },
    {
        "text": "suggest any additional analysis you recommend doing to arrive at an answer that takes into consideration all aspects required to provide a recommendation."
    },
    {
        "text": "remember, you may not dive into each possible aspect during the interview, but broadly stating them helps the interviewer understand that you\u2019re able to look at the bigger picture and can look into the details when needed."
    },
    {
        "text": "additionally, state any risks you see with the recommendation you\u2019re making."
    },
    {
        "text": "at each step, remember to take the time to pause and think, and you\u2019ll do great!"
    },
    {
        "text": "part 3 showcasing the right experience"
    },
    {
        "text": "tell me about a project you worked on over the course of writing this book, i spoke to interviewers and interviewees both."
    },
    {
        "text": "almost every person i spoke to mentioned asking or being asked the question, \u201ctell me about a project you worked on,\u201d in an interview."
    },
    {
        "text": "i probed my interviewers a little further, and some of them said this was in fact one of their favorite questions to ask!"
    },
    {
        "text": "the reason was that the easiest way for an interviewer to find out how good a candidate is was by asking them about work they did previously."
    },
    {
        "text": "discussion on past projects isn\u2019t unique only to data science interviews but can be seen in almost any interview."
    },
    {
        "text": "nailing this question down will help you come across as thorough and showcase your potential value to the interviewer."
    },
    {
        "text": "what is an interviewer looking for?"
    },
    {
        "text": "an interviewer is largely looking for the breadth and depth of your knowledge when asking you this question."
    },
    {
        "text": "let\u2019s dive into the specifics of what an interviewer is looking for."
    },
    {
        "text": "breadth: ability to explain a project you worked on from start to end: the interviewer will be looking at how you communicate what the project was about, what was done overall, what your specific contribution was, and what value was generated."
    },
    {
        "text": "an effective response here shows the interviewer you have an understanding of the entire pipeline of work."
    },
    {
        "text": "ability to articulate the business problem and how the project connects to"
    },
    {
        "text": "the company\u2019s broader strategic objectives: the project you were working on had a specific problem statement, of course, but its implementation would have helped fulfill an overarching strategic objective of the company."
    },
    {
        "text": "when you answer what the project was about, connecting it to the company\u2019s objectives, you show that you have an understanding of the bigger picture and the larger impact your specific project has on the company\u2019s goals."
    },
    {
        "text": "interaction among teams: even an individual contributor role requires, to some extent, collaboration with people across teams."
    },
    {
        "text": "your work may have involved working with the business to understand the problem statement in detail, with the data engineering team to get the data, or with the end users to test the intuitiveness of the results."
    },
    {
        "text": "demonstrating your ability to work with people from different teams displays interpersonal skills, a key in making a successful data scientist."
    },
    {
        "text": "ability to communicate impact of analytics solution: to achieve buy-in from the appropriate stakeholders, it is imperative to be able to quantify the impact of the analytical solution and communicate it across the board."
    },
    {
        "text": "this becomes key when driving adoption of the solution you\u2019re working on."
    },
    {
        "text": "depth: approach to solution building: a great candidate is able to talk through the different options thought of and evaluated before one is selected."
    },
    {
        "text": "when explaining the approach, you should share details on any requirements or constraints taken into consideration."
    },
    {
        "text": "technical details of the solution: this question can be a great segue for the interviewer to dive into some of the technical details of the project."
    },
    {
        "text": "for example, if you built a predictive model as part of the project, be prepared to answer questions about the model: how does it work?"
    },
    {
        "text": "what parameters did you tune?"
    },
    {
        "text": "how did you evaluate model fit?"
    },
    {
        "text": "is the model scalable?"
    },
    {
        "text": "data used: for any analytical role, you must have a detailed understanding of the data involved in solving the problem."
    },
    {
        "text": "the interviewer could go into details and ask questions along the lines of, what data was used to conduct the analysis?"
    },
    {
        "text": "why that data specifically?"
    },
    {
        "text": "how did you do the data collection?"
    },
    {
        "text": "did you face any challenges when collecting the data?"
    },
    {
        "text": "ability to synthesize technical information for a business audience: being able to explain the technical nuances of the project in simple layman\u2019s terms is important."
    },
    {
        "text": "while the interviewer will look for you to explain the inner workings of the models, the ability to explain things to a nontechnical audience is equally important."
    },
    {
        "text": "framework to answer the question now that we have a fair understanding of what the interviewer is looking for, let\u2019s take a stab at how best to answer this question."
    },
    {
        "text": "i have put together a rudimentary framework you can use for this."
    },
    {
        "text": "feel free to use this framework as a baseline and customize to your specific projects."
    },
    {
        "text": "brief overview of the project in two to three lines \u2013 what was the problem statement?"
    },
    {
        "text": "\u2013 what was the solution?"
    },
    {
        "text": "\u2013 what was the impact?"
    },
    {
        "text": "deep dive into the problem statement approach to problem-solving \u2013 what were the various options available to solve the problem?"
    },
    {
        "text": "\u2013 what option was chosen and why?"
    },
    {
        "text": "deep dive into the technical details of the solution \u2013 what were some of the challenges faced during solution implementation?"
    },
    {
        "text": "impact created and roi calculation \u2013 state the impact and roi from the project \u2013 walk through how this was measured and calculated practice question interviewer: can you tell me about a project you worked on?"
    },
    {
        "text": "candidate: sure."
    },
    {
        "text": "in the last year, i built a dashboard as part of the larger workforce analytics project to track the key metrics around incoming job applications."
    },
    {
        "text": "the goal of the project was to increase efficiency and effectiveness of talent acquisition."
    },
    {
        "text": "with the insights generated using the dashboard, the recruiting managers were able to track against the critical metrics and identify opportunities for improvements."
    },
    {
        "text": "the talent team was able to reduce the time to hire by 15 percent and the cost to hire by 22 percent over the course of the next quarter."
    },
    {
        "text": "i was primarily involved with building of the dashboard in powerbi as part of this project."
    },
    {
        "text": "i worked closely with our talent teams to understand the use case requirements, and in the process, i gained an in-depth understanding of the data available to build to dashboard."
    },
    {
        "text": "interviewer: that sounds excellent."
    },
    {
        "text": "can you walk me through what data you used to build the dashboard and the key metrics you tracked?"
    },
    {
        "text": "candidate: absolutely."
    },
    {
        "text": "once i had an understanding of the dashboard requirements, i worked with our it team to find the relevant sources of the data."
    },
    {
        "text": "let me first walk you through the metrics i tracked and then dive into the data sources if that works."
    },
    {
        "text": "interviewer: sure, no problem."
    },
    {
        "text": "candidate: as the overall goal of the project was to increase efficiency and effectiveness of the talent acquisition process, i broke down the hiring outcomes in the following way: efficiency average cost to hire average time to hire applicants to interview invites ratio interview to offer ratio effectiveness average retention rate over six and twelve months from hire"
    },
    {
        "text": "average individual performance rating over six and twelve months from hire the efficiency metrics were geared more toward how the talent acquisition process works, and tracking them over time will provide insight into how the process can be improved."
    },
    {
        "text": "the effectiveness metrics looked at how successful the hiring process was after the event."
    },
    {
        "text": "furthermore, i provided a drill down into each of these metrics by recruitment source."
    },
    {
        "text": "for example, we found that the cost to hire via referrals was on average 15 percent lower than other sources such as linkedin or external recruiting agencies."
    },
    {
        "text": "the retention and individual performance rating for employees coming in via referrals was also higher compared to the other sources."
    },
    {
        "text": "another drill down that i added was to show these metrics by different business units."
    },
    {
        "text": "using this drill down, we found that the number of referrals was very low for one business unit compared to the others."
    },
    {
        "text": "this alluded to the employee satisfaction being low for that business unit and was an actionable insight for our management."
    },
    {
        "text": "now, coming to the data sources, i primarily used the data within our human resources management system."
    },
    {
        "text": "we had tables that stored employee information, hiring source details, pipeline and budget allocations, and interview process details."
    },
    {
        "text": "i also merged in data from tables that had performance ratings for all employees."
    },
    {
        "text": "i organized meetings between our talent teams and the it team to ensure i was mapping the right data source to the appropriate metric."
    },
    {
        "text": "these open conversations allowed us to be on the same ."
    },
    {
        "text": "interviewer: great."
    },
    {
        "text": "i think you mentioned earlier you used powerbi to create the dashboards."
    },
    {
        "text": "any specific reason for the choice of that tool versus others?"
    },
    {
        "text": "candidate: that\u2019s a great question."
    },
    {
        "text": "so, during the initial discussions, we looked at what the different options were from a visualization perspective with tableau, qlikview, and powerbi being the primary ones given their ease of implementation and ability to create interactive visualizations."
    },
    {
        "text": "the primary reason we were in favor of powerbi was its low cost and company- wide access, as it is part of the microsoft 365 enterprise suite."
    },
    {
        "text": "although tools"
    },
    {
        "text": "like tableau are excellent in handling large amounts of data, for our use case we were typically dealing with only about one hundred thousand rows, so processing large amounts of data was not a concern."
    },
    {
        "text": "powerbi, like other tools, provided the capability to directly link to the ms sql server tables to access the data for the visualizations."
    },
    {
        "text": "essentially, we were able to make use of all the visualization functionality for our use case at a lower cost, and that drove the decision in favor of powerbi."
    },
    {
        "text": "interviewer: that sounds good."
    },
    {
        "text": "thank you for walking me through this project that you worked on."
    },
    {
        "text": "sounds like this was well received by the people in your company and was a success."
    },
    {
        "text": "candidate: absolutely."
    },
    {
        "text": "we were able to launch the dashboard for the talent team to access within two months, and the dashboard was very well received by the business overall."
    },
    {
        "text": "in fact, because of this project, our analytics team got exposure to the hr data present in the system, and i recommended the use of machine learning techniques to predict employee churn based on factors such as performance rating, appraisals, employee satisfaction surveys, and leaves taken."
    },
    {
        "text": "this idea was liked by the business and hr teams, and my team and i are currently working on its implementation."
    },
    {
        "text": "interviewer: that\u2019s very well thought out and will add value to the organization."
    },
    {
        "text": "thank you for your time today."
    },
    {
        "text": "comments: choosing a project to talk about is a mix of what you feel confident about and the type of role you\u2019re applying for."
    },
    {
        "text": "note in this case, the candidate chose to speak about a data analysis and data visualization project."
    },
    {
        "text": "this would be a good choice for a role that requires these skill sets and also requires you to liaise between different teams."
    },
    {
        "text": "remember that not every project you talk about needs to be machine learning driven or predictive modeling type of work."
    },
    {
        "text": "you can use examples where you have done extensive data analysis, gathered requirements to define analytics use cases, or built data visualizations to give strategic recommendations."
    },
    {
        "text": "and these are just a few examples\u2014there\u2019s definitely a lot out there in terms of the different data science related projects that you can talk about."
    },
    {
        "text": "if you\u2019re right out of college or if this is the first job you\u2019re applying for, you can talk about a project you did as part of your coursework or something you"
    },
    {
        "text": "self-initiated and did outside of school."
    },
    {
        "text": "differentiator: notice how the candidate gave a quick view into the recommendation they made to the talent team to leverage data analytics for their work further."
    },
    {
        "text": "time permitting in an interview, you can always add what you think could bring further value to the team/company based on your work."
    },
    {
        "text": "this will showcase to your interviewer that you continually think of the next steps, are able to think of the bigger picture, and give recommendations based on your analysis."
    },
    {
        "text": "expect to be asked this question in an interview in some shape or form."
    },
    {
        "text": "prepping at least two to three projects you can talk about in depth during your interview will set you up for success."
    },
    {
        "text": "presentation interview the ultimate goal for data science is to help make better business decisions."
    },
    {
        "text": "to enable this, the data scientist must convert data into actionable insights and communicate the results of their technical analysis to an executive audience in a concise manner."
    },
    {
        "text": "when i spoke to interviewers about how they were testing a candidate\u2019s ability to communicate, the topic of presentation interviews came about."
    },
    {
        "text": "based on my conversations with interviewers across companies, i found that presentation interviews are currently popular among product and consulting companies."
    },
    {
        "text": "they typically work in two ways: 1. interviewers allow the candidate to choose a project of their choice or 2. interviewers give a specific problem statement they want the candidate to work on and present the results for."
    },
    {
        "text": "in the first scenario, you are primarily expected to present a past project from start to finish, including the approach you took to solve the problem and the findings that came out of it."
    },
    {
        "text": "in the latter case where a problem statement or case prompt is given to you, interviewers will often share with you a supporting data set."
    },
    {
        "text": "you will use this data set to answer the questions stated and present your key findings."
    },
    {
        "text": "presentation interviews usually happen toward the end of the interview process."
    },
    {
        "text": "this means you can expect it after technical screening rounds are done and before behavioral interviews occur."
    },
    {
        "text": "these interviews are forty-five to sixty minutes in duration, with the first fifteen to twenty minutes reserved"
    },
    {
        "text": "for the candidate to make the presentation."
    },
    {
        "text": "the next fifteen to twenty minutes are slotted for the interviewers to ask you questions on your presentation, and the remainder time is for candidate\u2019s questions to the interviewer."
    },
    {
        "text": "what is an interviewer looking for?"
    },
    {
        "text": "you will notice that acing a presentation interview is in some ways similar to answering the question, \u201ctell me about a project you worked on,\u201d which we discussed previously."
    },
    {
        "text": "the similarities are in what the interviewer expects to see from the candidate, and this is applicable for both scenarios in which you either choose your own topic for presentation or you\u2019re given a specific question to answer."
    },
    {
        "text": "let\u2019s quickly recap the themes we looked at in the last chapter."
    },
    {
        "text": "these speak to the interviewer expectations for the presentation interview and also for the \u201ctell me about a project you worked on\u201d questions: ability to explain a project you worked on from start to end ability to articulate the business problem approach to problem-solving depth of technical knowledge ability to synthesize technical information for a business audience ability to communicate impact of analytics solution how do you prepare for a presentation interview?"
    },
    {
        "text": "with a handle on what the interviewer expectations are, let us now move on to a few pointers that will be helpful as you prepare for a presentation interview."
    },
    {
        "text": "tell it like a story: describing a project you have worked on is best done when you look at it like narrating a story."
    },
    {
        "text": "irving wladawsky-berger in a street journal blog emphasizes the importance of storytelling in business: \u201cgood storytelling is particularly important when introducing a complex and potentially disruptive offering in the marketplace whose value is not well understood."
    },
    {
        "text": "it\u2019s a natural way of explaining what the new innovation is all about.\u201d22"
    },
    {
        "text": "what irving says is especially true for data science projects because the inner workings of machine learning techniques can be quite complex, but they can also be a differentiator in bringing value to the business."
    },
    {
        "text": "to encourage adoption of these techniques, the impact from such projects needs to be communicated effectively."
    },
    {
        "text": "and the skill to articulate the complex nature of data science is exactly the skill any employer is looking for when hiring a data scientist."
    },
    {
        "text": "tailor it to your audience: what you narrate largely depends on the audience you are speaking to."
    },
    {
        "text": "for the presentation interview, understand from the recruiter who the audience is going to be."
    },
    {
        "text": "in most interviews, you can expect a panel that consists of a technical and a nontechnical audience."
    },
    {
        "text": "your nontechnical audience primarily wants to understand what the business problem was and what value you created or impact you made by implementing your solution."
    },
    {
        "text": "your technical audience will go into the details of the approach you used and the chosen solution."
    },
    {
        "text": "collectively, they want to see if you are adept at communicating what you worked on from start to end."
    },
    {
        "text": "this is especially important because as a data scientist, you will talk to people from different teams on a regular basis."
    },
    {
        "text": "these people could be anyone from the leadership, data engineering team, fellow data scientists, developers, end users, etc."
    },
    {
        "text": "make it visual: edward tufte explained the value of good visuals perfectly when he said, \u201cgraphical excellence is that which gives to the viewer the greatest number of ideas in the shortest time with the least ink in the smallest space.\u201d23 here\u2019s the thing, though: putting together good visuals is easier said than done."
    },
    {
        "text": "but investing time in them is generally worth it!"
    },
    {
        "text": "visualizations tend to catch your audience\u2019s attention quickly and also allow you to creatively share the key messages you want to highlight in a presentation."
    },
    {
        "text": "from a data science perspective, you can make use of visualizations to show data/insights with the use of charts, histograms, heat maps, plots, word clouds, etc."
    },
    {
        "text": "these allow you to organize your data better and also show more information in a smaller space."
    },
    {
        "text": "anticipate the questions: once you have laid out your story board, flip the hat you are wearing and think from the interviewer\u2019s perspective."
    },
    {
        "text": "if you were the interviewer, what questions would you ask to understand the details of the project?"
    },
    {
        "text": "while this is not an exhaustive list, you can expect questions along the lines of: \u2013 why did you choose this methodology specifically?"
    },
    {
        "text": "\u2013 did you consider any alternative approaches?"
    },
    {
        "text": "why or why not?"
    },
    {
        "text": "\u2013 if you were to do this project again, what would you do differently?"
    },
    {
        "text": "\u2013 what were some of the key challenges you faced when working on this project?"
    },
    {
        "text": "\u2013 what was the response you got when you presented the key findings from this project?"
    },
    {
        "text": "\u2013 can you explain the analytical technique used to an executive audience?"
    },
    {
        "text": "if you have some extra time on your hands, putting together a couple slides that speak to the anticipated questions could be worthwhile."
    },
    {
        "text": "you can add these slides in the appendix and bring them up in the conversation if needed."
    },
    {
        "text": "this shows that you have thought through multiple facets of the project and will set you apart from other candidates."
    },
    {
        "text": "do a practice run: once you have the presentation ready and you\u2019ve worked on the anticipated questions, it\u2019s time to do a mock run!"
    },
    {
        "text": "the best way to do it is to present to a friend live and have them ask you the list of questions you have identified."
    },
    {
        "text": "see how you do in the practice run and improvise from there."
    },
    {
        "text": "get feedback from your friend and identify any gaps in the presentation you can address."
    },
    {
        "text": "a useful tactic here could be recording this conversation and playing to see for yourself how you did."
    },
    {
        "text": "if your friend happens to be in the field of data science, have them roleplay and wear the hat of a technical and a nontechnical audience."
    },
    {
        "text": "if your friend isn\u2019t from a data science background, have them probe your understanding of the business problem and the value you created with your solution."
    },
    {
        "text": "doing this even once will set you up for success in the presentation interview."
    },
    {
        "text": "how do you structure and story board the presentation?"
    },
    {
        "text": "now, let\u2019s come to the meat of this chapter!"
    },
    {
        "text": "how would you structure and story board your presentation?"
    },
    {
        "text": "below, i have provided an elementary guideline you can use when you put together the presentation."
    },
    {
        "text": "executive summary \u2013 what was the problem statement?"
    },
    {
        "text": "\u2013 why was this important to the business?"
    },
    {
        "text": "\u2013 broadly, how was the problem solved?"
    },
    {
        "text": "\u2013 what value did the solution bring?"
    },
    {
        "text": "deep dive into the company and problem statement \u2013 what does the company do and what is its business model?"
    },
    {
        "text": "\u2013 what is the exact business problem the company is facing?"
    },
    {
        "text": "\u2013 what are the different parameters involved in the problem?"
    },
    {
        "text": "solution overview \u2013 was there a need for an analytical solution and why?"
    },
    {
        "text": "\u2013 what are the different options available to solve this problem?"
    },
    {
        "text": "\u2013 what type of analytical solution was used and why?"
    },
    {
        "text": "\u2013 what are some of the technical details behind the solution implementation?"
    },
    {
        "text": "\u25a0highlight any special considerations value created \u2013 what was the value created?"
    },
    {
        "text": "\u2013 how did you measure the impact?"
    },
    {
        "text": "\u2013 how did this translate to hard dollars for the company (if applicable)?"
    },
    {
        "text": "in situations where the impact wasn\u2019t measured, state the approach in which it could have been done."
    },
    {
        "text": "this can be applicable for a presentation where the"
    },
    {
        "text": "company gives you the problem statement to solve for."
    },
    {
        "text": "it\u2019s always good to show your thought process on how you would do it if you had all the information needed."
    },
    {
        "text": "feel free to make and state any assumptions while doing so."
    },
    {
        "text": "the guidelines in this chapter will put you in a great spot, but the key is to practice so you can sound like the pro you are in your interview!"
    },
    {
        "text": "22 irving wladawsky-berger, \u201cthe growing importance of storytelling in the business world,\u201d the wall street journal, march 17, 2017."
    },
    {
        "text": "23 edward tufte, the visual display of quantitative information, (cheshire: graphics press, 2001)."
    },
    {
        "text": "take-home exam let\u2019s say you just got off the phone with the recruiter about an open data science role."
    },
    {
        "text": "it looks like a great fit based on your discussion, and now you\u2019re awaiting the next steps when you receive the following email: \u201cwe are excited to move further in the interview process with you."
    },
    {
        "text": "the next step in the process is a data science assessment that you will take remotely."
    },
    {
        "text": "please find the instructions enclosed.\u201d so how do you now prepare for it?"
    },
    {
        "text": "in this chapter, i will walk you through what to expect in these take-home exams and give you tips on how to crack them."
    },
    {
        "text": "take-home exams are a popular screening technique and sometimes are used even before you have a live interview with someone from the company."
    },
    {
        "text": "they are often part of the technical screening process of the interview and are designed to mostly mimic the type of work you may be expected to perform."
    },
    {
        "text": "the company will likely evaluate you against the key skill sets they need in their data scientist."
    },
    {
        "text": "the format of these varies from company to company."
    },
    {
        "text": "based on my research, i have found the following two formats popularly used: 1. online assessment: depending on the company, you may be asked to complete a coding challenge on interview platforms like hackerrank, coderbyte, and code signal."
    },
    {
        "text": "these tests vary in duration but typically take between one to three hours, and you have the flexibility to choose the programming language you want to code in."
    },
    {
        "text": "often, the platform tests you against the completeness of the code, correctness of the result, and the speed"
    },
    {
        "text": "at which you developed the solution."
    },
    {
        "text": "2. custom take-home assessment: some companies may ask you to complete a take-home data science project."
    },
    {
        "text": "as part of this, they usually give you a broader business statement to tackle and an accompanying data set to use to solve the problem."
    },
    {
        "text": "these projects can be completed from anywhere between six to ten hours."
    },
    {
        "text": "again, most companies give you the flexibility in choosing the programming language you want to work in."
    },
    {
        "text": "what is an interviewer looking for?"
    },
    {
        "text": "i spoke to a couple of senior data scientists and when it comes to evaluating performance, this is the rubric they mentioned the most: problem-solving skills: this is one of the key elements of the rubric you may be tested against."
    },
    {
        "text": "the evaluator wants to see your ability to comprehend the problem statement, break it down into smaller tasks, and develop a solution and recommendation."
    },
    {
        "text": "code-writing skills: these exams are designed to test whether you have the basic code-writing skills expected of a data scientist."
    },
    {
        "text": "speed: in an online exam where tracking of completion time is possible, you may also be evaluated on the speed with which you can code."
    },
    {
        "text": "completeness: in the scenario that you aren\u2019t able to fully complete the test, you may be evaluated against what portion of the test you were able to complete."
    },
    {
        "text": "pro tip: in cases where getting through the whole challenge appears difficult to you, address the key questions first and tackle secondary questions later."
    },
    {
        "text": "what should you expect in a take-home exam?"
    },
    {
        "text": "if you\u2019re asked to complete such an exam, you can typically expect a few tasks types: query language: you may be asked to perform data operations like joining two tables, aggregating key columns to generate metrics, and other basic operations such as filtering, sorting, case when, and if/else statements."
    },
    {
        "text": "some tests may look at your know-how of advanced sql techniques like use of window functions in sql."
    },
    {
        "text": "predictive modeling: you may be asked to build a predictive model, either classification or regression in most cases, and be asked to score a test data set."
    },
    {
        "text": "clustering: you can be given an unsupervised learning problem and be asked to develop clusters that are statistically sound and that have the desired business application."
    },
    {
        "text": "probability and statistics basics: in some cases, you can expect to see multi- choice questions testing you on probability and statistics basics."
    },
    {
        "text": "for probability these could be around conditional probability, bayes\u2019 theorem, etc."
    },
    {
        "text": "for statistics, these could be around p-values or z-scores."
    },
    {
        "text": "i have provided sample questions and answers on these topics in : probability, statistics, experimental design."
    },
    {
        "text": "data interpretation: i have seen product and consulting companies ask data interpretation questions, especially if the role has a heavier \u201cdata analytics\u201d component to it."
    },
    {
        "text": "you may be given a raw or summarized data set and be asked to answer specific questions or to generate insights from the data set."
    },
    {
        "text": "most of these questions are posed in the business context and may require you to make a formal recommendation to the business on the problem you\u2019re asked to solve."
    },
    {
        "text": "how should you prep for take-home exams?"
    },
    {
        "text": "here are a few things you can do to prepare before you are even asked to take an assessment at home: create an often-used code library: you can build out basic functions in a programming language of your choice so you have them handy when you have to work on a take-home project."
    },
    {
        "text": "if you\u2019re assigned an online assessment and aren\u2019t allowed access to any outside material during the exam, building out these functions can be great practice and will help you code faster during the test."
    },
    {
        "text": "here are a few functions you can consider building out: \u2013 impute missing values \u2013 plots to do exploratory data analysis \u2013 building out summary statistics on a data set \u2013 train and score a classification and regression model"
    },
    {
        "text": "practice coding exercises: you can practice coding challenges on online platforms like coderbyte, hackerrank, leetcode, and codesignal."
    },
    {
        "text": "most of these online platforms offer free exercises for you to practice."
    },
    {
        "text": "doing this well ahead of time will help you evaluate where you are when it comes to tackling these tests and address any gaps you see beforehand."
    },
    {
        "text": "it is also very helpful to familiarize yourself with at least a couple of these platforms so that you know how you can write, run, test, and debug the code on these websites."
    },
    {
        "text": "you may lose time learning to navigate the test environment if you see it for the first time on the day of your test."
    },
    {
        "text": "pro tip: before you are given the assessment, check with the recruiter on what format you can expect the areas you will be tested on and the rubric you will be scored with."
    },
    {
        "text": "your recruiter may have already given you this information, but in case they haven\u2019t, you can always ask this question so you can adequately prepare for it."
    },
    {
        "text": "to ace these tests, you should practice beforehand and make sure your fundamentals in programming and data science concepts are solid."
    },
    {
        "text": "although they may seem daunting initially, with sufficient practice, you will be able to ace them."
    },
    {
        "text": "extra questions for practice: you have been given a data set containing five columns titled a, b, c, d, e with numeric data that contains test scores corresponding to a subject."
    },
    {
        "text": "the scores range between zero to one hundred, and each row corresponds to a student."
    },
    {
        "text": "with this data, build clusters of students that show similar performance on tests."
    },
    {
        "text": "the clusters created will be used by the teachers to understand the strengths and weaknesses of the group and build customized teaching plans for each."
    },
    {
        "text": "you are given stock prices for three stocks over the last two years."
    },
    {
        "text": "predict the stock prices for the next month."
    },
    {
        "text": "the data is at a daily level with the stock price at close of business."
    },
    {
        "text": "you have a table named \u201csquares\u201d given to you that has four columns."
    },
    {
        "text": "each column contains a number that corresponds to the length of a side."
    },
    {
        "text": "add another column to this table called \u201cflag,\u201d which is a boolean"
    },
    {
        "text": "(true/false)."
    },
    {
        "text": "the column \u201cflag\u201d will be true if it is a square."
    },
    {
        "text": "note that if all four sides are equal then flag as true."
    },
    {
        "text": "behavioral interview a behavioral interview can be a free playground to test the candidate on the skills that are core to the company."
    },
    {
        "text": "put yourself in the shoes of the interviewer and you will understand their thought process."
    },
    {
        "text": "the interviewer is probably thinking: do i want this person on my team?"
    },
    {
        "text": "can i rely on and trust this person?"
    },
    {
        "text": "is this person a good team player?"
    },
    {
        "text": "can this person start contributing to the project straight away?"
    },
    {
        "text": "can this person handle stressful situations and navigate conflict?"
    },
    {
        "text": "now, let\u2019s discuss how you can best prepare for this kind of interview."
    },
    {
        "text": "what is an interviewer looking for?"
    },
    {
        "text": "behavioral interviews are quite common for a lot of job roles, but your interviewer may be looking for a few specific things that are key to the data science field."
    },
    {
        "text": "here\u2019s a breakdown of the rubric you may be tested on: reactive versus proactive: when given a task, do you just do what you\u2019re told, or do you bring in your point of view to the job and enhance the solution?"
    },
    {
        "text": "to illustrate this point further, let\u2019s look at the following conversation."
    },
    {
        "text": "joon lim, a data science leader at linkedin, spoke to the students of northwestern university as part of eunhee ko\u2019s class."
    },
    {
        "text": "here\u2019s a snippet of that transcript that lays this out beautifully."
    },
    {
        "text": "question asked by a student: i am curious to hear more about the difference"
    },
    {
        "text": "between junior and senior data scientists."
    },
    {
        "text": "what\u2019s expected of a junior data scientist (ds), and what makes senior data scientists senior?"
    },
    {
        "text": "joon\u2019s response: you may be expecting answers like a more in-depth understanding of ml algorithms such as deep learning, more effective partnership management, and more engaging presentation."
    },
    {
        "text": "these technical skills and soft skills are all important, but i believe the real differentiator is the ability to make proactive contributions."
    },
    {
        "text": "junior ds tend to be reactive to business partners."
    },
    {
        "text": "the partners make prescriptive requests to a junior ds who just focuses on delivering the result."
    },
    {
        "text": "business partner: \u201chey joon, could you help check how many linkedin members are seeing this promotion for a week?\u201d junior ds: \u201csure, here is the number that you are looking for: 25m.\u201d business partner: \u201cthank you.\u201d joon\u2019s comment: junior ds don\u2019t bother to understand the motivation behind the question and tend to quickly jump into the conclusion."
    },
    {
        "text": "some argue this is effective in building trust and relationships with partners."
    },
    {
        "text": "i don\u2019t disagree, but this type of contribution is limited as you assume the prescriptive direction that your partner outlined is the most effective in solving the business problem at hand."
    },
    {
        "text": "instead, senior ds would seek to understand the motivation and think together on the best way to achieve the fundamental objective."
    },
    {
        "text": "business partner: \u201chey joon, could you help check how many linkedin members are seeing this promotion for a week?\u201d senior ds: \u201csure, i can help you get this number, but first, could you help me understand how you plan to use this data for?\u201d business partner: \u201coh, i think the promotion targeting criteria is too stringent.\u201d senior ds: \u201cokay, then i\u2019d suggest looking into the underlying eligibility distribution instead, and we can check whether it makes sense to move the threshold."
    },
    {
        "text": "but if we loosen up the criteria, we may face potential side effects such as increasing member complaints, unsubscriptions, turning off the promo setting, etc.\u201d"
    },
    {
        "text": "business partner: \u201cgot it, that makes sense to me."
    },
    {
        "text": "could you help find the sweet spot?\u201d senior ds: \u201cof course, i should be able to get back to you by this friday.\u201d business partner: \u201cawesome, thank you.\u201d24 when framing your answers, focus on being proactive and demonstrate how you added value on top of what was expected."
    },
    {
        "text": "culture fit: culture fit is a two-way street."
    },
    {
        "text": "the organization you want to work for should be a fit for you as much as you should be a fit for them."
    },
    {
        "text": "culture fit questions can revolve around the following: why do you want to work for our company?"
    },
    {
        "text": "how do you see yourself fitting into our company?"
    },
    {
        "text": "how do you handle stress or tight deadlines?"
    },
    {
        "text": "how do you handle failures?"
    },
    {
        "text": "would you rather work alone or with a team?"
    },
    {
        "text": "how do you like to lead and delegate?"
    },
    {
        "text": "how do you like to be managed?"
    },
    {
        "text": "these are a few questions you can expect in the culture fit assessment."
    },
    {
        "text": "but the idea here is to see if both parties involved are compatible with each other for a successful stint."
    },
    {
        "text": "it's just as important for you to be happy with the company as it is for the company to be happy with you."
    },
    {
        "text": "conflict resolution and stressful situations: the interviewer may ask you to describe situations where you had to resolve a conflict or work through any times that were stressful on the project."
    },
    {
        "text": "while there may not be an exact right or wrong answer to these types of questions, the interviewer is looking to understand your working style and if it aligns with the company\u2019s overall culture."
    },
    {
        "text": "stories to prepare when preparing for behavioral interviews, you will set yourself up for success if you prepare key examples/instances, or \u201cstories,\u201d as i prefer to call them."
    },
    {
        "text": "depending on the question, you can pick the story to highlight during your"
    },
    {
        "text": "interview."
    },
    {
        "text": "while i am categorizing them under wide umbrellas here, stories under these headlines can be customized to many different questions asked in a behavioral interview."
    },
    {
        "text": "the key is to have this list handy so you have a strong base to go in with for your interview."
    },
    {
        "text": "describe an instance when you... led a team handled and resolved a conflict went out of your way to make a project successful went outside of your comfort zone faced a challenging situation on one of your projects failed and how you adapted to the situation approach: alternative what-how technique to answer behavioral questions, i suggest using the alternative what-how technique."
    },
    {
        "text": "let\u2019s walk through the details below: what was it?"
    },
    {
        "text": "briefly describe the project, problem statement being solved, and parties involved."
    },
    {
        "text": "think of this part as setting the stage for your answer."
    },
    {
        "text": "how was it done?"
    },
    {
        "text": "in this part, describe the details of the task and the work done to complete it."
    },
    {
        "text": "state any other alternatives that were taken into consideration, if applicable."
    },
    {
        "text": "this is a great way to set yourself apart by showcasing that you evaluated other options before finalizing the approach you took."
    },
    {
        "text": "what did you do?"
    },
    {
        "text": "once you have set the stage and described the task at hand, walk the interviewer through your specific contributions."
    },
    {
        "text": "this is where the \u201ci vs. we\u201d differentiator comes into picture."
    },
    {
        "text": "while the full team\u2019s contributions are key to make any project successful, your specific part in it is what you need to highlight."
    },
    {
        "text": "how did you bring value?"
    },
    {
        "text": "round up the answer by summarizing the impact the project made and how your work brought value to the team and the organization."
    },
    {
        "text": "let us now look at a practice question."
    },
    {
        "text": "practice questions practice question #1 interviewer: can you tell me about a time when you were asked to complete some work in an accelerated time frame than what was decided earlier?"
    },
    {
        "text": "candidate: sure."
    },
    {
        "text": "in my current role, i am part of a centralized data science team, and i work with different functions within the organization on data- driven projects."
    },
    {
        "text": "the instance that i want to share with you is about a project i was working on with the marketing team."
    },
    {
        "text": "we were working on an analysis leading to an optimization solution that allowed the marketers to optimize digital marketing campaign spend to target the right audience."
    },
    {
        "text": "this in turn would optimize the organization\u2019s marketing budget."
    },
    {
        "text": "the full project, as such, was scoped and the time frame based on the scope decided was two months."
    },
    {
        "text": "however, a week into the project, our marketing team reached out to us and told us to deliver this project within a week from then."
    },
    {
        "text": "this was quite accelerated given the scope of work involved."
    },
    {
        "text": "although my immediate reaction was that what they are asking for is just not feasible, i took a step back, tried to understand where they were coming from, and then set up a conversation with them to understand the need behind the request for accelerated delivery."
    },
    {
        "text": "from that conversation, i understood that the business was pushing to close campaigns on a particular channel, and it wanted to use our solution to gather the data/insights it needed to counter this decision if necessary."
    },
    {
        "text": "now, that made sense to me."
    },
    {
        "text": "i explained to the business that we could pull the data and help it with the analysis it needed to determine the impact of pulling the campaigns from that channel within a week."
    },
    {
        "text": "and i proposed that we keep this as the short-term goal for the project and retain the original scope and timing"
    },
    {
        "text": "for the larger optimization project."
    },
    {
        "text": "the business agreed to this, and i was able to work with the marketing team to understand their detailed requirements and then with the data engineering team to track the exact data sources we needed to hit to pull the data for this analysis."
    },
    {
        "text": "we collaborated across teams in an agile fashion and delivered the analysis to the marketing team."
    },
    {
        "text": "we then put forth a recommendation to the business of not pulling that campaign channel down as the impact on revenue would be considerable, and the roi from the channel wasn\u2019t as low as the business suspected."
    },
    {
        "text": "comments: overall, the candidate did a good job in demonstrating how they delivered value in an accelerated time frame and how they navigated the ask from the marketing team."
    },
    {
        "text": "the candidate was able to break down the task into what was an immediate priority versus long term and promptly delivered what was imperative to the business."
    },
    {
        "text": "the candidate was also able to show their ability to collaborate and communicate effectively to get things done."
    },
    {
        "text": "practice question #2 interviewer: can you tell me a situation where you handled conflict at work?"
    },
    {
        "text": "candidate: sure."
    },
    {
        "text": "on a recent project, i led a team of three junior data scientists."
    },
    {
        "text": "the project had tight deadlines and very specific deliverables tied to each milestone."
    },
    {
        "text": "each of us was focusing on a deliverable and tracking against the timeline in place."
    },
    {
        "text": "however, for one of the milestones, a deliverable that my teammate was working on wasn\u2019t ready, and there was a potential that we would be late."
    },
    {
        "text": "i checked in with my teammate and asked why the deliverable was running late."
    },
    {
        "text": "they did not receive that question well and got very defensive."
    },
    {
        "text": "i quickly realized my question could have been worded better to make them feel more comfortable to talk about the issues at hand."
    },
    {
        "text": "we decided to take a small break from that conversation and talk again in a few minutes."
    },
    {
        "text": "i took the time to collect my thoughts and then met with my teammate again."
    },
    {
        "text": "when we spoke at length, they told me they had other competing priorities with similar tight deadlines and that is why they were running late on the project we were working on together."
    },
    {
        "text": "i sat down with them and made a list of"
    },
    {
        "text": "all the items they were working on and met with the team lead of their other project."
    },
    {
        "text": "together, we were able to shuffle a few items and reorganize their priorities without impacting any deadlines."
    },
    {
        "text": "i took up a few tasks from their list and had my other team members lean in too so we could collectively cover ground."
    },
    {
        "text": "interviewer: sounds like you handled the situation well."
    },
    {
        "text": "were there any learnings from this that you used moving forward?"
    },
    {
        "text": "candidate: yes, in fact i updated our planning process so that our full team has visibility into all of the projects we are working on and how much bandwidth each team member has by week."
    },
    {
        "text": "this allowed me to prioritize task items better and reallocate as necessary."
    },
    {
        "text": "comments: if you are interviewing for a managerial role, the interviewer will want to know how you lead your junior team members and how you deal with any challenging situations that crop up as part of being a lead on the project."
    },
    {
        "text": "notice in this question how the candidate effectively managed to continually improve as a leader while being receptive to the input from their juniors."
    },
    {
        "text": "in conclusion, when you are asked a question in a behavioral interview, take a few minutes at the outset to identify an example that would be the most fitting for the question asked."
    },
    {
        "text": "with that example in mind, lay out the structure in which you want to talk through the story."
    },
    {
        "text": "taking some time in the beginning will help you navigate the question well and will lead to meaningful conversation with the interviewer."
    },
    {
        "text": "extra questions for practice: tell me about an instance where you solved a challenging problem."
    },
    {
        "text": "have you worked under pressure or a stressful situation in the past?"
    },
    {
        "text": "how did you handle it?"
    },
    {
        "text": "tell me about an instance where you failed at something, and how did you navigate that situation?"
    },
    {
        "text": "has there been a time when you pitched an idea to senior leadership, and what was the outcome?"
    },
    {
        "text": "24 eunhee (emily) ko, \u201ca conversation with joon lim about data science at linkedin,\u201d linkedin.com, accessed june 07, 2020."
    },
    {
        "text": "part 4 putting your best foot forward"
    },
    {
        "text": "crafting a data science resume your resume is a snapshot of who you are, what you have done so far, and what potential you have to offer."
    },
    {
        "text": "when you\u2019re applying for jobs, you don\u2019t want your resume to get lost in the mythical black box that never gets opened after the first read."
    },
    {
        "text": "you may be an excellent data scientist with the best git repository of analytics solutions, but if your resume isn\u2019t up to par, then you may not get a call back from the company you\u2019re applying to."
    },
    {
        "text": "cracking an interview gets you the job, but an excellent resume is what gets you in the door!"
    },
    {
        "text": "in their book cracking the pm interview, gayle laakmann mcdowell and jackie bavaro speak about the 15 second rule."
    },
    {
        "text": "they say, \u201ca resume isn\u2019t read; it\u2019s skimmed."
    },
    {
        "text": "a resume screener will glance at your resume for about 15 seconds (or maybe less) to make a decision about whether or not to interview you.\u201d25 this is exactly why a resume is crucial and the first step you need to get right when applying for jobs."
    },
    {
        "text": "pro tip: my biggest advice when creating a resume is to objectively take some time out to build it."
    },
    {
        "text": "by investing this time early on, you can, in one shot: create a solid and favorable resume prepare for a \u201cresume-based\u201d interview how do you do these two things at once?"
    },
    {
        "text": "you can do this using what i call \u201cthe hundred-word story.\u201d"
    },
    {
        "text": "the hundred-word story the hundred-word story is a framework i put together that will help you naturally build out a resume and prepare for interview questions based on it."
    },
    {
        "text": "at some point in the interview process, you can expect questions on the projects that you have mentioned on your resume."
    },
    {
        "text": "instead of spending additional time prepping for those, with the hundred-word story framework, you can do both at once."
    },
    {
        "text": "you can use the framework by following the steps below: step 1: list out each project that you have done in the past that you think is a good candidate to talk about in any interview or to go on your resume."
    },
    {
        "text": "step 2: write an approximately hundred-word story on each project, answering the questions below: what was the project\u2019s overarching objective?"
    },
    {
        "text": "what was your role and contribution on the project?"
    },
    {
        "text": "what impact was made by the work you did?"
    },
    {
        "text": "step 3: write another hundred-word story answering the questions below: why did you choose the approach that you used to solve the problem?"
    },
    {
        "text": "what were the major challenges you faced during this project?"
    },
    {
        "text": "is there anything you would do differently now that the project is done?"
    },
    {
        "text": "if you do these above three steps correctly, you will not only prepare solid content for your resume, but you\u2019ll also have material handy for any resume- based questions that pop up in an interview."
    },
    {
        "text": "let\u2019s walk through an example of this so we can see how it plays out."
    },
    {
        "text": "hundred-word story #1 the marketing team within our company wanted to build a positioning strategy for one of the cosmetic products that our company sells."
    },
    {
        "text": "they wanted to do this to drive revenue growth for that line of product."
    },
    {
        "text": "i worked"
    },
    {
        "text": "with the marketing and it teams to develop the customer segments."
    },
    {
        "text": "following this, i identified the most profitable target segment for that product."
    },
    {
        "text": "the marketing team then used the insights from the segmentation to position the product in the market."
    },
    {
        "text": "the new and improved positioning of the product enabled a potential market gain of $1.2 million over the quarter after it was launched."
    },
    {
        "text": "hundred-word story #2 i chose to segment the customers using the k-means clustering technique and used the elbow curve to find the optimal number of segments."
    },
    {
        "text": "i also tried the agglomerative clustering technique, but i found more meaningful results using the k-means technique."
    },
    {
        "text": "i compared the mean and standard deviations of each cluster across the two techniques to assess their performance."
    },
    {
        "text": "we used survey data to create the clusters, and designing meaningful features from those was a bit challenging."
    },
    {
        "text": "in retrospect, i would involve the business stakeholders from early on, in this case the marketing team, so their input into feature engineering and result validation could be built into the process and not just taken at the end."
    },
    {
        "text": "now that we have our two stories in place, let\u2019s look at how we use them."
    },
    {
        "text": "the first story is what you will use to craft a bullet on your resume."
    },
    {
        "text": "let\u2019s look at a very basic way to do this and then at an improved example of the same thing."
    },
    {
        "text": "basic example: developed customer segments using k-means techniques to help the marketing team position a product."
    },
    {
        "text": "segmentation was done in python."
    },
    {
        "text": "new and improved example: enabled a potential market gain of 1.2 million by improving the positioning strategy of a cosmetic product."
    },
    {
        "text": "the new product positioning was driven by identifying the most profitable segment."
    },
    {
        "text": "customer segmentation developed was based on survey data and involved use of k-means clustering implementation in python."
    },
    {
        "text": "comments: notice how in the basic example, the candidate leaves out the impact made by their project."
    },
    {
        "text": "when you lead with the impact or at least mention it as part of your bullet, you demonstrate that you have an understanding of how your data science work drives business decisions."
    },
    {
        "text": "let us now look at a sample resume to get a full picture of what a data science resume can look like."
    },
    {
        "text": "sample resume jane doe education north carolina state university m.s., analytics (2010\u20132012) san francisco state university (2005\u20132008) b.s., computer science work experience cosmoline (2012\u2013present) data scientist enabled a potential market gain of 1.2 million by improving the positioning strategy of a cosmetic product."
    },
    {
        "text": "the new product positioning was driven by identifying the most profitable segment."
    },
    {
        "text": "customer segmentation developed was based on survey data and involved use of k-means clustering implementation in python."
    },
    {
        "text": "decreased customer churn by 3 percent by building a model to isolate the factors causing churn so immediate action could be taken to increase retention."
    },
    {
        "text": "churn model was built in r based on logistic regression technique and pca for feature reduction."
    },
    {
        "text": "cut down call duration for the customer care team by 27 percent by identifying the most commonly asked questions with the use of text mining ziofy (2008\u20132010) product analyst coordinated with the data engineering and product teams to design and build a metric tracking dashboard in tableau for the launch of a new product"
    },
    {
        "text": "feature."
    },
    {
        "text": "streamlined process to track metrics for other future feature launches saving 2-week analyst work effort each time to do this process."
    },
    {
        "text": "analyzed external data and provided recommendations on competitive trends."
    },
    {
        "text": "insights generated were leveraged to reduce loss of customers to competitor offerings."
    },
    {
        "text": "awards and activities outstanding performance award during the capstone case study project \u2014 corporate development program, ziofy."
    },
    {
        "text": "president of quarterly data science hackathon at ncsu that involves participation from 100+ students from computer science, analytics, industrial engineering, and other departments."
    },
    {
        "text": "event raised $5000 in prize money with sponsorship from tech giants including facebook, google, and microsoft."
    },
    {
        "text": "languages and tools programming languages: python, r, sas, java, sql database: experience working with microsoft sql server, mysql, oracle, sybase visualization tools: tableau, qlikview, powerbi additional information kaggle rank 87 as of dec 2019 active blog contributor for \u201ctowards data science\u201d on medium.com your resume is a gateway to any job you want, and this makes it one of the most important things you will work on in the entire job application and interview process."
    },
    {
        "text": "hence, take the time to build a solid resume and make sure to use the hundred-word story technique we discussed in this chapter."
    },
    {
        "text": "this way, not only will you have a strong resume, but you\u2019ll also be sufficiently prepared for any interview questions based off of your resume."
    },
    {
        "text": "and as always, get it reviewed by a friend so you have a second set of eyes to give you 360- degree feedback!"
    },
    {
        "text": "25 gayle laakmann mcdowell and jackie bavaro, cracking the pm interview: how to land a product manager job in technology (palo alto: careercup, 2013)."
    },
    {
        "text": "data science portfolio if you talk to any artist or creative professional, you will realize that the majority will showcase their work with the help of a portfolio."
    },
    {
        "text": "a portfolio is nothing but a collection of work samples that documents their professional accomplishments and offers demonstrable proof of their work."
    },
    {
        "text": "it\u2019s a great way to showcase conceptual, creative, technical, and presentation abilities."
    },
    {
        "text": "why build a portfolio for data science?"
    },
    {
        "text": "\u201cnow, why consider building a portfolio for data science?\u201d you may ask, and rightly so."
    },
    {
        "text": "if you set aside the technical and mathematical aspects of data science, then it is as much art as it is science."
    },
    {
        "text": "weeding through rows and rows of data to find something substantial needs scientific prowess, no doubt, but this skill also requires a certain creative ability to ask the right questions and tease out the insights."
    },
    {
        "text": "working on a canvas and seeing it evolve day by day is analogous in many ways to the work of a data scientist."
    },
    {
        "text": "let\u2019s say, for example, you are building a machine learning model and start by exploring your playing field, i.e., the data."
    },
    {
        "text": "you work through the variables to see what makes sense to include in the model and iterate on different features and modeling methodologies before you paint the final picture."
    },
    {
        "text": "the whole process is very discovery-based, and a portfolio in some ways does justice to demonstrate in a tangible fashion the thought process and the amount of work going behind building the final product."
    },
    {
        "text": "another strategic reason to build a portfolio is because it allows you to play to your strengths."
    },
    {
        "text": "data science as a field in itself is so varied and has wide- ranging skill sets in demand in the market."
    },
    {
        "text": "you may be someone who writes efficient, flawless code designed to be scalable from the get-go or you may be"
    },
    {
        "text": "someone who can narrate complex analytical findings in a simple visual fashion."
    },
    {
        "text": "with the help of a portfolio you can showcase where in the large scheme of things your specialty lies and in what areas you can contribute from day one."
    },
    {
        "text": "who can/should build one?"
    },
    {
        "text": "anyone in the industry can build and use a portfolio to showcase their skills."
    },
    {
        "text": "it\u2019s an excellent way to differentiate yourself from your competitors when applying for a job."
    },
    {
        "text": "if you fall into any of these three categories or a combination of them, you can benefit from building a data science portfolio: you are looking for your first job: consider building a portfolio if you\u2019re right out of college looking for your first job or if you have limited work experience."
    },
    {
        "text": "a portfolio is an excellent way to put forth tangible work products that speak to your credibility as a data scientist."
    },
    {
        "text": "you are new to data science: if you have a few years of work experience under your belt but it\u2019s not directly classified as data science currently, you can build a portfolio to showcase your potential in the field."
    },
    {
        "text": "additionally, you will be able to strengthen the case for things you are already good at your current job."
    },
    {
        "text": "for example, you are a software developer looking to move into a machine learning engineer role."
    },
    {
        "text": "having a github account with machine learning projects to show can help bridge that gap and land you the desired job."
    },
    {
        "text": "you are an experienced data scientist: if you are an experienced data scientist looking for your next big opportunity, you can tactically curate the different projects you\u2019ve worked on in the past to share with potential employers."
    },
    {
        "text": "this will allow you to play to your strengths and get you in the door of a company of your choosing."
    },
    {
        "text": "what can you include?"
    },
    {
        "text": "when building a portfolio, show what you can do well\u2014and what you can do extremely well\u2014to make yourself stand apart."
    },
    {
        "text": "you don\u2019t have to tick every box when building a portfolio, but show the things you\u2019re really good at because what may appeal to one company may not appeal to the other."
    },
    {
        "text": "by"
    },
    {
        "text": "showcasing your strengths and being recruited for those, not only does a company find a good fit in you, you find a good fit in the company."
    },
    {
        "text": "that being said, depending on where your strengths lie, you can showcase your skills using any of the following."
    },
    {
        "text": "please note this is not an exhaustive list but rather a sample of different avenues that can be explored when building a data science portfolio."
    },
    {
        "text": "projects on github: sharing your github repository with concrete project examples lends you certain credibility and shows that you have the confidence to share and speak about the projects you have worked on at a detailed level."
    },
    {
        "text": "your projects on github can span a wide range of topics, including but not limited to exploratory data analysis, super or unsupervised learning models, descriptive data analysis, and data cleaning."
    },
    {
        "text": "kaggle: kaggle hosts data science competitions and is often a great way to practice solving data science problems."
    },
    {
        "text": "you can also see how you compare against folks in the industry."
    },
    {
        "text": "you can leverage kaggle projects to show your rankings in the competition or as a way to share your approach to analytical problem solving."
    },
    {
        "text": "dashboard/visualizations: explaining complex analytical concepts in simple visualizations that are intuitive to an executive audience is often challenging."
    },
    {
        "text": "if you\u2019re able to depict your data and insights in a visual fashion, showcase this ability in your portfolio."
    },
    {
        "text": "it is a crucial skill to have and is a quick win in the eyes of a potential employer."
    },
    {
        "text": "blogs: another great way to get the word out about your skills and interests is to blog."
    },
    {
        "text": "you can present your point of view to the world using your blog and demonstrate thought leadership in the field."
    },
    {
        "text": "or you can use your blog to show your technical and nontechnical communication skills."
    },
    {
        "text": "youtube videos: often, teaching is the fastest way to learn something."
    },
    {
        "text": "if you are passionate about a certain data science area, you can create training/informational videos on that topic and share."
    },
    {
        "text": "you don\u2019t have to do this for the sake of building a portfolio but if it is something you enjoy doing, then take a stab at it, and your portfolio will build itself."
    },
    {
        "text": "presentation: do you like making slides and telling a story?"
    },
    {
        "text": "put together a presentation of a project you worked on."
    },
    {
        "text": "being able to narrate a story through"
    },
    {
        "text": "slides shows your ability in written and visual communication."
    },
    {
        "text": "in summary, a data science portfolio isn\u2019t mandatory for every candidate to have, but if you have the time and passion to build one, it can go a long way."
    },
    {
        "text": "it\u2019s an excellent technique to practice and showcase your skills."
    },
    {
        "text": "in the process of creating a portfolio, you might even build a network of people who have similar interests as you."
    },
    {
        "text": "part 5 last but not the least"
    },
    {
        "text": "wrapping up now that you have reached the end of this book, i hope you understand the different aspects of a data science interview and have a good handle on how to crack each round."
    },
    {
        "text": "before we wrap up, though, i want to share a few pointers about optimizing your job application process."
    },
    {
        "text": "what to look for when applying to jobs you should know a few things about the company you are applying to and the role you are applying for."
    },
    {
        "text": "this can be done by digging into three key areas."
    },
    {
        "text": "1. company: as you prepare for your interview, here are a few things you should learn about the company."
    },
    {
        "text": "a. the company\u2019s culture, mission, and values."
    },
    {
        "text": "b. its primary business and how its business model works."
    },
    {
        "text": "c. the key players in the organization."
    },
    {
        "text": "d. latest news articles about the company."
    },
    {
        "text": "2. people: the people perspective is more of a spin on how the teams within the company are structured."
    },
    {
        "text": "typically, you might observe one of these two organizational structures in place at most companies: a. a centralized data science team."
    },
    {
        "text": "b. dedicated data science teams embedded within different functions."
    },
    {
        "text": "simply understanding how the teams are structured will give you a sense of"
    },
    {
        "text": "what to expect in the interview."
    },
    {
        "text": "for example, let\u2019s say the data scientists are embedded within the specific product teams."
    },
    {
        "text": "you can expect interview questions around that product, and you could potentially hypothesize the kind of cases they ask you and then study in depth the relevant analytical techniques generally used for working on those problems."
    },
    {
        "text": "3. technology: while the company aspect answers who they are and the people piece answers who does what, the technology piece will help answer how do they do it."
    },
    {
        "text": "researching this bit will help you understand things like... a. is it a python shop, an r shop, or something else?"
    },
    {
        "text": "b. does it emphasize on certain skill sets like data visualization, storytelling, and presentation skills?"
    },
    {
        "text": "c. how is its infrastructure set up?"
    },
    {
        "text": "what technology should you be familiar with to work with its infrastructure?"
    },
    {
        "text": "once you narrow down the company and role you want to apply to, try to get an informational interview with a current employee to learn more about the company culture and the work they do."
    },
    {
        "text": "you can do this by reaching out to someone you may know directly or by asking a mutual connection."
    },
    {
        "text": "knowing these things will not only help you be prepared for your interviews but will also allow you to evaluate if the company/role is a fit for you."
    },
    {
        "text": "at the same time, remember you don\u2019t need to have answers to all the questions i have mentioned above."
    },
    {
        "text": "if you can\u2019t find answers to some of these questions, ask them in your interview to learn more about the company and role."
    },
    {
        "text": "based on my experience, some of these led to excellent conversations with my interviewers."
    },
    {
        "text": "it also gave me an insight into how favorable this job would be for me if i were to get an offer and accept it."
    },
    {
        "text": "i say this to anyone i talk to when it comes to a job hunt\u2014it\u2019s a two-way street."
    },
    {
        "text": "you should like them as much as they like you!"
    },
    {
        "text": "in closing when it comes to cracking a job interview, no substitute exists for adequate practice."
    },
    {
        "text": "reach out to people within your network and ask them to conduct mock"
    },
    {
        "text": "interviews for you."
    },
    {
        "text": "be it case interviews, coding challenges, or behavioral interviews, you will feel very confident in an actual interview when you have practiced a few times."
    },
    {
        "text": "practicing with the use of mock interviews will help you tackle these situations with confidence."
    },
    {
        "text": "in the context of identifying what areas to practice on, eric weber, gm of experimentation & data science leader at yelp, gave me the following advice: \u201ccandidates should push for details about what the interview process entails."
    },
    {
        "text": "although this could be tough to do in a candidate\u2019s position, doing so gives you a structure to base your preparation on.\u201d leverage your recruiter to understand the role in depth and what to expect as part of the interview process."
    },
    {
        "text": "they are an excellent resource and want to see you succeed."
    },
    {
        "text": "lastly, remember to brush up on your fundamentals before any interview and know in depth about the projects you\u2019ve worked on."
    },
    {
        "text": "you can capitalize on the sample answers given in this book and use them as a frame of reference when tackling a question in an interview."
    },
    {
        "text": "even if you encounter a completely new question, you will be able to think on your feet using the frameworks and structure mentioned in this book."
    },
    {
        "text": "i am confident that if you are passionate about data science and diligent in your preparation as recommended in my book, you will certainly be an outlier in the recruiting process and land the job that you want!"
    },
    {
        "text": "all the best."
    },
    {
        "text": "stay in touch."
    },
    {
        "text": "https://www.linkedin.com/in/shrilata-murthy/"
    },
    {
        "text": "acknowledgments i started writing this book when i was pregnant with my daughter, samyra."
    },
    {
        "text": "so, it is safe to say that i have never been alone when writing this book."
    },
    {
        "text": "and this has been true throughout the journey."
    },
    {
        "text": "i have had all-around support from my family, friends, publishing team, and my beta readers during the course of writing be the outlier."
    },
    {
        "text": "writing a book is hard work."
    },
    {
        "text": "for every sentence you write, you wonder if it could have been structured differently."
    },
    {
        "text": "for every idea you discuss, you ponder if another one would have been more appropriate."
    },
    {
        "text": "for every chapter you include, you probe whether you said everything you wanted to say."
    },
    {
        "text": "it is an intense and grueling process and one that is not possible without a solid support system."
    },
    {
        "text": "i deeply appreciate everyone who has supported me in this process."
    },
    {
        "text": "to my best friend and husband, ganapati."
    },
    {
        "text": "you are the pillar that always stood strong when i needed you."
    },
    {
        "text": "thank you for always being there for me."
    },
    {
        "text": "to my beautiful daughter, samyra."
    },
    {
        "text": "one day you will be old enough to read this book and know how you were always next to mumma every step of the way."
    },
    {
        "text": "to my family, shrikant murthy, vijaya murthy, mythili payyalur, shrideep murthy, rutuja deshpande, lakshmi kollengode, and anand kuppaswamy."
    },
    {
        "text": "thank you for always encouraging me to do my best."
    },
    {
        "text": "to my data science support system, alice zhao, andy fox, aniket deshpande, anirban bhattacharya, anthony tockar, arindam paul, biswanath banik, chris pease, diego klabjan, ehsan rehman, eric weber, gaurav dhingra, kyle hundman, laura siahaan, macario lullo, peter schmidt, samar kaushal, shantanu raghav, and shel singh."
    },
    {
        "text": "thank you for"
    },
    {
        "text": "being so willing to ideate with me and for providing excellent input."
    },
    {
        "text": "with your collective help, i was able to metamorphose all ideas into this very book."
    },
    {
        "text": "to my publishing team from new degree press, eric koester, brian bies, emily price, and jennifer psujek."
    },
    {
        "text": "with your help, this book has come into being."
    },
    {
        "text": "to my beta readers, i could not have done this without you."
    },
    {
        "text": "your support early on in the process made publishing this book possible."
    },
    {
        "text": "abhishek kedia ahsan rehman ameer khan ameeta japtiwale amit rao amol khor amruta pathak anand kuppaswamy andrew fox aniket deshpande anirban bhattacharya anisha gurumurthy ankit koradia ankita nagori anupama mangalvedhe aprit arora apurva limaye ashwini senan"
    },
    {
        "text": "biswanath banik cinjal shah corey n paulish daniel medina darryl malcolm dcosta devon weiss dr. halasya ramanathan eric koester erika enomoto faza chugtai g. ragunathan ganapati raghunathan garima singh hema chandra chittuluri jake whitesides jayanth srinivasan kalyani patil kapil gadhire karthik sastry kedar guttikar ketan patil ketki gandhe kirti khopkar krutika vyas"
    },
    {
        "text": "kushal mahajan lakshmi kollengode laura siahaan macario lullo manasi mangalvedhe meghana mangalvedhe miranda zhu namesh kher naveen shankar neil jones nikhil khekade nikhil nambiar nitin mangalvedhe nisha shetty nistarani ramanathan nithya hariharan northwestern university, master of science in analytics p.s."
    },
    {
        "text": "mythili parul deswal peter j. schmidt pooja sunder pratap kaul preeti ramaraj prithvi mali"
    },
    {
        "text": "rahul goswami rajalakshmi balan ravindar kumar richa kumari riddhi bhatt rohit bhangale ronak parpani rutuja deshpande salil sabade sandesh doddameti sanjeevni wanchoo saurabh jha saurabh vishwas joshi shantanu raghav shel singh shilpa sreekrishnan shirish gupta shivee singh shraddha hegde shreya thacker shreyans mulkutkar shreyas tendulkar shrideep murthy shrikant murthy"
    },
    {
        "text": "shruti jalali sneha paul sneha tiku soumyajit mallick tanmay shah umananthini abhishek varsha jagdale varshini ramaraj venky munivenkata vignesh venkatachalam vijaya murthy vikesh chauhan vishal pareek vivek ajmera william chiu xiaowei li yahya cheema yugandhar garde to you, my reader."
    },
    {
        "text": "thank you for choosing to read this book and joining me in the data science journey."
    },
    {
        "text": "additional resources database systems hector garcia-molina, jeffrey d. ullman, jennifer d. widom, database systems: the complete book, 2nd edition, prentice hall, 2009. ramakrishnan, raghu and johannes gehrke."
    },
    {
        "text": "\"database management systems.\""
    },
    {
        "text": "3rd edition."
    },
    {
        "text": "new york: mcgraw-hill, 2002 sql leetcode."
    },
    {
        "text": "category \u2013 database."
    },
    {
        "text": "https://leetcode.com/problemset/database/ w3school."
    },
    {
        "text": "sql tutorial."
    },
    {
        "text": "https://www.w3schools.com/sql/ select star sql."
    },
    {
        "text": "https://selectstarsql.com/ hackerrank."
    },
    {
        "text": "practice sql."
    },
    {
        "text": "https://www.hackerrank.com/domains/sql codeacademy."
    },
    {
        "text": "learn sql."
    },
    {
        "text": "https://www.codecademy.com/learn/learn-sq python python.org."
    },
    {
        "text": "the python tutorial."
    },
    {
        "text": "https://docs.python.org/3/tutorial/index.html codeacademy."
    },
    {
        "text": "learn python."
    },
    {
        "text": "https://www.codecademy.com/learn/learn- python-3 udacity."
    },
    {
        "text": "programming foundations with python."
    },
    {
        "text": "https://www.udacity.com/course/introduction-to-python--ud1110 google."
    },
    {
        "text": "google\u2019s python class."
    },
    {
        "text": "https://developers.google.com/edu/python/ practicepython."
    },
    {
        "text": "beginner python exercises."
    },
    {
        "text": "http://www.practicepython.org/ r"
    },
    {
        "text": "grolemund, garett and hadley wickham."
    },
    {
        "text": "r for data science."
    },
    {
        "text": "sebastopol: o\u2019reilly, 2017 tidyverse."
    },
    {
        "text": "r packages for data science."
    },
    {
        "text": "https://www.tidyverse.org/ ismay chester and albert y. kim \u201cstatistical inference via data science: a moderndive into r and the tidyverse.\u201d boca raton: crc press, 2020."
    },
    {
        "text": "appendix introduction indeed hiring lab, us."
    },
    {
        "text": "\u201cdata scientist: a hot job that pays well.\u201d accessed may 5, 2020 cao, sissi."
    },
    {
        "text": "\u201cwhat on earth is a data scientist?"
    },
    {
        "text": "the buzzword\u2019s inventor dj patil spills all.\u201d observer, november 9, 2019. https://observer.com/2019/11/data-scientist-inventor-dj-patil-interview-linkedin- job-market-trend/ linkedin."
    },
    {
        "text": "\u201clinkedin: 2020 emerging jobs report.\u201d accessed may 16, 2020. https://business.linkedin.com/content/dam/me/business/en-us/talent-solutions/emerging-jobs- report/emerging_jobs_report_u.s._final.pdf davenport, thomas h. and d.j."
    },
    {
        "text": "patil."
    },
    {
        "text": "\u201cdata scientist: the sexiest job of the 21st century.\u201d harvard business review, october 2012 issue."
    },
    {
        "text": "https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the- 21st-century linkedin."
    },
    {
        "text": "\u201clinkedin: 2020 emerging jobs report.\u201d accessed may 16, 2020. https://business.linkedin.com/content/dam/me/business/en-us/talent-solutions/emerging-jobs- report/emerging_jobs_report_u.s._final.pdf dummies."
    },
    {
        "text": "\"the importance of clustering and classification in data science.\""
    },
    {
        "text": "dummies."
    },
    {
        "text": "accessed may 17, 2020. https://www.dummies.com/programming/big-data/data-science/the-importance-of- clustering-and-classification-in-data-science/ hyndman, r.j., & athanasopoulos, g. (2018) forecasting: principles and practice, 2nd edition, otexts: melbourne, australia."
    },
    {
        "text": "otexts.com/fpp2."
    },
    {
        "text": "accessed may 17, 2020. metcalfe, andrew v. and paul s.p."
    },
    {
        "text": "cowpertwait."
    },
    {
        "text": "introductory time series with r. (new york: springer, 2009), 81 morde, vishal."
    },
    {
        "text": "\u201cxgboost algorithm: long may she reign!\u201d medium.com."
    },
    {
        "text": "accessed may 20, 2020. https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she- may-rein-edd9f99be63d introduction to probability and statistics."
    },
    {
        "text": "conditional probability, independence and bayes\u2019 theorem class 3, 18.05. spring 2014. massachusetts institute of technology: mit opencouseware,"
    },
    {
        "text": "https://ocw.mit.edu/."
    },
    {
        "text": "license: creative commons by-nc-sa."
    },
    {
        "text": "investopedia.com."
    },
    {
        "text": "\u201ccompound probability.\u201d accessed june 5, 2020. https://www.investopedia.com/terms/c/compound-probability.asp math goodies."
    },
    {
        "text": "\u201cconditional probability\u201d."
    },
    {
        "text": "accessed may 17, 2020. https://www.mathgoodies.com/lessons/vol6/conditional mba crystal ball."
    },
    {
        "text": "\u201cprobability | theory, solved examples and practice questions\u201d."
    },
    {
        "text": "accessed may 17, 2020. https://www.mbacrystalball.com/blog/2015/07/03/probability/ mcginely, patton."
    },
    {
        "text": "\u201ctests of change: simulated design of experiments in healthcare delivery\u201d."
    },
    {
        "text": "patient safety & quality healthcare, july 14, 2009. https://www.psqh.com/analysis/tests-of-change/ statistics how to."
    },
    {
        "text": "\u201cconditional probability: definition & examples\u201d."
    },
    {
        "text": "accessed may 17, 2020. https://www.statisticshowto.com/probability-and-statistics/statistics-definitions/conditional- probability-definition-examples/ study.com."
    },
    {
        "text": "\u201cprobability of compound events: definition & examples.\u201d accessed june 5, 2020. https://study.com/academy/lesson/probability-of-compound-events-definition-examples-quiz.html tufte, edward."
    },
    {
        "text": "the visual display of quantitative information."
    },
    {
        "text": "cheshire: graphics press, 2001. wladawsky-berger, irving."
    },
    {
        "text": "the growing importance of storytelling in the business world.\u201d the wall street journal, march 17, 2017. https://blogs.wsj.com/cio/2017/03/17/the-growing-importance-of- storytelling-in-the-business-world/ ko, eunhee (emily)."
    },
    {
        "text": "\u201ca conversation with joon lim about data science at linkedin\u201d linkedin.com."
    },
    {
        "text": "accessed june 07, 2020. https://www.linkedin.com/pulse/conversation-joon-lim-data-science-linkedin- eunhee-emily-ko/ laakmann mcdowell, gaye, and jackie bavaroman."
    },
    {
        "text": "cracking the pm interview: how to land a product manager job in technology."
    },
    {
        "text": "palo alto: careercup, 2013."
    },
    {
        "text": "about the author shrilata murthy is a practicing data scientist with experience in statistical modeling, data mining, and data visualization."
    },
    {
        "text": "she holds a master\u2019s degree in analytics from northwestern university and a b.e."
    },
    {
        "text": "in information technology from mumbai university."
    },
    {
        "text": "as a programmer-turned-data scientist, murthy now enjoys consulting to help improve data-driven decision making."
    },
    {
        "text": "when she\u2019s not building machine-learning models, murthy loves spending time with her daughter and going for outdoor runs."
    },
    {
        "text": "her debut book be the outlier: how to ace data science interviews is a practical guide for any novice or experienced data scientist looking to improve their interview technique."
    }
]